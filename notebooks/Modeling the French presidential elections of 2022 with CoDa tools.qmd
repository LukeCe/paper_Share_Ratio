---
title: "Modeling the French presidential elections of 2022 with CoDa tools"
author:
  - Lukas Dargel
  - Christine Thomas-Agnan
format:
  html:
    theme: minty
    toc: true
    number-sections: true
    code-fold: true
    code-tools: true
    df-print: kable
    embed-resources: true
    standalone: true
    self-contained: true
execute:
  cache: true
  fig-show: hold
---

```{r}
#| include: false
dir.create(here::here("out","figures"),showWarnings = FALSE,recursive = TRUE)
dir.create(here::here("out","tables"),showWarnings = FALSE,recursive = TRUE)
```



```{r setup}
#| warning: false
#| message: false
library("colorspace")
library("CoDaImpact")
library("compositions")
library("data.table")
library("here")
library("ggplot2")
library("kableExtra")
library("skimr")
library("stringr")
library("zCompositions")

save_baseplot <- function(device, ..., which){
  suppressMessages({
    dev.copy(device, ..., which)
    dev.off()
    invisible(TRUE)
  })
}
format_VarTab <- function(VT, digits = 4, digitsU = max(digits - 2, 0), digitsP = digits,  digitsPP = digits) {
  VT <- t(VT)
  VT <- as.data.frame(round(VT, digits))
  
  v <- "Variation in units"
  if (!is.null( VT[[v]])) VT[[v]] <- round(VT[[v]], digitsU)
  
  v <- "Variation in %"
  if (!is.null( VT[[v]])) VT[[v]] <- paste0(round(VT[[v]], digitsP), " %")
  
  v <- "Variation in % points"
  if (!is.null( VT[[v]])) VT[[v]] <- paste0(round(VT[[v]], digitsPP), " %")
  t(VT)
}

options(knitr.kable.NA = '',
        scipen = 9,
        warn = 1)

mun_elec2census <- readRDS(here("out/data/mun_elec2census.Rds")) # election data combined with the census
mun_elec <- readRDS(here("in/data/mun_elec.Rds")) # original election data 
```


The vignette illustrates results of the article from Dargel and Thomas-Agnan (2023).


# Introduction

We illustrate the use of CoDa tools to analyse the results of political elections based on the example of the French presidential elections of 2022.
Our main focus lays on the illustration of mathematical tools that enable new ways for interpretation of CoDa models.
Other issues such as the selection of explanatory variables and the treatment of zeros are treated more briefly.


# Descriptive statistics

The study combine the official election results with census data.

  -  [The original census data is available on the INSEE website](https://www.insee.fr/fr/statistiques/6543200#consulter)
  -  [The official election results are provided by the French government and can be dowloaded here](https://www.data.gouv.fr/fr/datasets/election-presidentielle-des-10-et-24-avril-2022-resultats-definitifs-du-1er-tour/)
  

## Data overview 

Let us have a first look at the combined data set.

```{r}
skim(mun_elec2census)
```


## Compare losses due to preprocessing 

We lose some of the registered voters in France because the census data only covers individuals living in mainland France.
The overseas departments and voters living in a foreign country are not covered by our analysis.
Let us compare the original voting data with the combined voting data to assess the losses and potential biases.


```{r}
rename_elec <- c(
  MACRON_Emmanuel = "Macron",
  LE_PEN_Marine = "Le Pen",
  MELENCHON_Jean_Luc = "Mélenchon",
  LEFT = "Left",
  RIGHT = "Right",
  NON_VOTE = "No vote",
  ARTHAUD_Nathalie = "Arthaud",
  ROUSSEL_Fabien = "Roussel",
  LASSALLE_Jean = "Lasalle",
  ZEMMOUR_Eric = "Zemmour",
  HIDALGO_Anne = "Hidalgo",
  JADOT_Yannick = "Jadot",
  PECRESSE_Valerie = "Pécresse",
  POUTOU_Philippe = "Poutou",
  DUPONT_AIGNAN_Nicolas = "Dupont-Aignan",
  ABSTENTIONS = "Abstention",
  BLANK = "Blank",
  INVALID = "Invalid",
  EXPRESSED = "Expressed",
  REGISTERED = "Registered")

```


```{r}
# original election columns
elec_cols <- setdiff(names(mun_elec), c("ID_MUN", "NAME_MUN", "NAME_DEP"))
pct <- function(x) scales::percent(x,accuracy = .1)
summarize_elec <- function(dt) {
  
  dt <- data.table(
    Municipalities = nrow(dt),
    Departements = length(unique(dt$NAME_DEP)),
    dt[,lapply(.SD, sum), .SDcols = elec_cols]
  )
  
  
  dt[,EXPRESSED := NA]
  dt[,REGISTERED := sum(.SD), .SDcols = elec_cols]
  dt[,EXPRESSED := REGISTERED - ABSTENTIONS - BLANK - INVALID]
  
  show_dt <- data.table(t(dt),keep.rownames = TRUE)
  
  dont_use <- c("Municipalities","Departements")
  show_dt[!rn %in% dont_use,
          "% of REGISTERED" := pct(V1/dt[["REGISTERED"]])]
  
  dont_use <- c(dont_use, "ABSTENTIONS", "BLANK", "INVALID", "REGISTERED")
  show_dt[!rn %in% dont_use,
          "% of EXPRESSED" := pct(V1/dt[["EXPRESSED"]])]
  names(show_dt)[1:2] <- c("Indicator", "Count")
  show_dt
}  

elec_original <- summarize_elec(mun_elec)
elec_combined <- summarize_elec(mun_elec2census)
elec_combined <- cbind(Loss = elec_original[["Count"]] - elec_combined[["Count"]], elec_combined[,-1])
elec_combined <- cbind("% Loss" = pct(elec_combined[["Loss"]]/elec_combined[["Count"]]), elec_combined)
elec_original[Indicator %in% names(rename_elec),Indicator := rename_elec[Indicator]]
kable(cbind(elec_original, elec_combined)) |> 
  kable_classic(full_width = F) |> 
  add_header_above(c(" " = 1, "Full election data" = 3, "Combined election data" = 5)) |> 
  pack_rows(group_label = "Units", 1,2,hline_after = TRUE) |> 
  pack_rows(group_label = "Not expressed", 3,5,hline_after = TRUE) |> 
  pack_rows(group_label = "Expressed", 6,17,hline_after = TRUE) |> 
  pack_rows(group_label = "Totals", 18,19,hline_after = TRUE) |> 
  column_spec(1, bold = T) 
```


## Check for problems with zeros

Since CoDa models do not handle zero proportions in the dependent and independent compositional variables we have to treat the problem of zero before we can estimate a the models.
We will first use amalgamations, followed by an imputation where we replace the remaining zeros with small values.
Th amalgamations consist in grouping multiple professional categories or political candidates into larger blocks.
While the grouping we propose is based our intuitive understanding a case study of the French electoral sociology should certainly place more thought in these actions.

### In the vote data

We first check for zeros in the dependent variables.

```{r}
zero_summary <- function(dt) dt[,lapply(.SD, function(x) pct(sum(x==0)/.N))]
t(zero_summary(mun_elec2census[,..elec_cols]))
```

One way to solve the problem is amalgamations.
We see that almost $98.5\%$ of observations are complete now.

```{r}
left_bloc <- c("ARTHAUD_Nathalie", "ROUSSEL_Fabien", "HIDALGO_Anne", "JADOT_Yannick", "POUTOU_Philippe")
right_bloc <- c("ZEMMOUR_Eric", "PECRESSE_Valerie", "LASSALLE_Jean", "DUPONT_AIGNAN_Nicolas")

VOTE <- cbind(
  mun_elec2census[,c("MACRON_Emmanuel", "LE_PEN_Marine", "MELENCHON_Jean_Luc")],
  LEFT = as.integer(rowSums(mun_elec2census[,..left_bloc])),
  RIGHT = as.integer(rowSums(mun_elec2census[,..right_bloc])),
  NON_VOTE = as.integer(rowSums(mun_elec2census[,c("ABSTENTIONS", "INVALID","BLANK"),])))

colnames(VOTE) <- rename_elec[colnames(VOTE)]

vote_names <- rename_elec[colnames(VOTE)]
zPatterns(
  VOTE,
  bar.labels = TRUE,
  label="0")
```

`r zv <- sum(0 != rowSums(VOTE == 0))`
The remaining zeros are imputed.
Here we simply add one vote to all candidates (or blocks) in each municipality with at least one zero.
For out `VOTE` composition we impute data in `r zv` municipalities which lead `r zv*ncol(VOTE)` additional registered voters.


```{r}
is_zero_row <- 0 != rowSums(VOTE == 0) 
VOTE_IMP <- VOTE + is_zero_row

cbind(
  sum(is_zero_row),
  sum(is_zero_row) * ncol(VOTE),
  sum(VOTE_IMP) - sum(VOTE))
```

#### Before and after

Let us check the impact of the imputation on the distribution of the data.
We see that our imputation leads an increase in the variance, but does not affect the average in a noticeable way.
This is expected because our imputation method replaces zeros (red bars in the graphic) with points close to the edge of the triangle, which are extreme values in the simplex sense.

```{r}
#| fig-show: "hold"

simplex_isodensity <- function(
  data,
  quantiles = c(0.5,1:9,9.5)/10,
  labels = names(cen),
  col1 = "black",
  col2 = "grey45",
  plot_data = TRUE) {
  
  # code adapted from:
  # Van den Boogaart and Tolosana-Delgado (2013), page 52
  
  stopifnot(ncol(data) == 3)
  cen <- mean(data)
  var <- var(data)
  if (plot_data) 
    plot(data, pch = ".", col = "grey85", labels = labels, mp = NULL, lenMissingTck = 0.02)
  plot(cen,pch=4, col = col1, labels = labels, add = plot_data)
  for (p in quantiles) {
    r = sqrt(qchisq(p=p,df=2))
    ellipses(cen,var,r, col=col2)
  }
}

opar <- par(mar=c(0,3,0,3), mfrow = c(1,2))
simplex_isodensity(acomp(VOTE_IMP[,1:3]))
title(sub = "Imputed", outer = FALSE)
simplex_isodensity(acomp(VOTE[,1:3]))
title(sub = "Original")
par(opar)
```

```{r}
#| fig-show: "hold"
opar <- par(mar=c(0,3,0,3), mfrow = c(1,2))
simplex_isodensity(acomp(VOTE_IMP[,-(1:3)]))
title(sub = "Imputed", outer = FALSE)
simplex_isodensity(acomp(VOTE[,-(1:3)]))
title(sub = "Original")
par(opar)
```



### In the professional categories (PC) data

The professional categories data directly comes from the French population census provided by the INSEE.
It categorizes the population above the age of 15 into one of eight groups.
The categories correspond to

  + `C19_POP15P_CS1`: Agriculteurs exploitants
  + `C19_POP15P_CS2`: Artisans, Commerçants, Chefs d'entreprise
  + `C19_POP15P_CS3`: Cadres et Professions intellectuelles supérieures
  + `C19_POP15P_CS4`: Professions intermédiaires
  + `C19_POP15P_CS5`: Employés
  + `C19_POP15P_CS6`: Ouvriers
  + `C19_POP15P_CS7`: Retraités
  + `C19_POP15P_CS8`: Autres sans activité professionnelle


```{r}
pc_cols <- names(mun_elec2census)
pc_cols <- pc_cols[grep("^C19_", pc_cols)]
t(zero_summary(mun_elec2census[,..pc_cols]))
```

Since the number of municipalities having zero share of some of these categories is to large we proceed with an amalgamation of the eight original groups into four broader categories.
Using the new categorization about  $95%$ of the municipalities have are complete.

```{r}
PROFCAT <- cbind(
  "Upper"   = mun_elec2census[,C19_POP15P_CS3 + C19_POP15P_CS4],
  "Workers" = mun_elec2census[,C19_POP15P_CS5 + C19_POP15P_CS6],
  "Retired" = mun_elec2census[,C19_POP15P_CS7],
  "Other"   = mun_elec2census[,C19_POP15P_CS1 + C19_POP15P_CS2 + C19_POP15P_CS8]
)

zPatterns(
  PROFCAT,
  label="0",
  bar.labels = TRUE,
  axis.labels = c(NA,NA))
```

`r zv <- sum(0 != rowSums(PROFCAT == 0))`
We impute the data using the same strategy as before.
Here we impute data in `r zv` municipalities leading to `r zv*ncol(PROFCAT)` additional "inscriptions".

```{r}
is_zero_row <- 0 != rowSums(PROFCAT == 0) 
PROFCAT_IMP <- PROFCAT + is_zero_row
cbind(
  sum(is_zero_row),
  sum(is_zero_row) * ncol(PROFCAT),
  sum(PROFCAT_IMP) - sum(PROFCAT))
```

#### Before and after imputation

We have the same results as before, but the increase in variance appears more pronounced.

```{r}
#| fig-show: "hold"
opar <- par(mar=c(0,4,0,4), mfrow = c(1,2))
simplex_isodensity(acomp(PROFCAT_IMP[,(1:3)]))
title(sub = "Imputed", outer = FALSE)
simplex_isodensity(acomp(PROFCAT[,(1:3)]))
title(sub = "Original")
par(opar)
```

```{r}
#| fig-show: "hold"
opar <- par(mar=c(0,3,0,3), mfrow = c(1,2))
simplex_isodensity(acomp(PROFCAT_IMP[,(2:4)]))
title(sub = "Imputed", outer = FALSE)
simplex_isodensity(acomp(PROFCAT[,(2:4)]))
title(sub = "Original")
par(opar)
```


# Exploratory analysis


We defined the data set for our analysis.
Which is based on the imputed vote and professional categories (PC) data.


```{r}
mun2explore <- data.table(
  ID_MUN = mun_elec2census$ID_MUN,
  REGISTERED = rowSums(VOTE_IMP))
mun2explore <- cbind(mun2explore, VOTE_IMP, PROFCAT_IMP)
```


## Concentration

(Not yet ready)


## Heteroskedasticity


Since election data corresponds to aggregations of individual choices we should suspect heteroskedasticity.
The scatter plot below shows that that the share of "non votes" is directly impacted by the total number of voters.
Additionally, its volatility seems to decrease with the size of the municipality in terms number if voters.

```{r}
#| warning: false
#| message: false
ggplot(mun2explore[REGISTERED < 300000,], aes(x = sqrt(REGISTERED), y = `No vote`/REGISTERED)) +
  geom_point() +
  geom_smooth() +
  theme_bw() +
  theme()
```

A similar pattern is observed for all vote variables.

```{r}
#| fig-show: hold
seq125 <- c(0, unlist(lapply(10^seq(10), "*", c(1,2,5))))
seqSqr <- seq(0,15)^2 * 1000 
namesSqr <- c(
  sprintf("..., %s]", seqSqr[-1]), 
  sprintf("(%s, ...", seqSqr[length(seqSqr)]))
mun2explore[,REGISTERED_BINS := cut(REGISTERED,c(seqSqr,Inf),labels = namesSqr)]
mun2explore_long <- 
  melt(mun2explore,
       id.vars = c("ID_MUN","REGISTERED_BINS"),
       measure.vars = colnames(VOTE))

mun2explore_long[,value_rel := value/sum(value), by = "ID_MUN"]
mun2explore_long[,variable:=factor(variable, levels = rename_elec)]
ggplot(mun2explore_long, aes(x = REGISTERED_BINS, y = value_rel)) +
  geom_boxplot(outlier.size = .1) +
  facet_wrap("variable", ncol = 3) +
  scale_y_continuous(name = "Vote share",labels = scales::percent) +
  labs(x = "Number of registered voters") +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90,hjust = 1,vjust = .5)) 

ggsave(here("out/figures", "vote6_boxplots.pdf"), width = 7, height = 6)
```


For the profession categories we have the same pattern.

```{r}
#| fig-show: hold
mun2explore_long2 <- 
  melt(mun2explore,
       id.vars = c("ID_MUN","REGISTERED_BINS"),
       measure.vars = colnames(PROFCAT))

mun2explore_long2[,value_rel := value/sum(value), by = "ID_MUN"]
ggplot(mun2explore_long2, aes(x = REGISTERED_BINS, y = value_rel)) +
  geom_boxplot(outlier.size = .1) +
  facet_wrap("variable", ncol = 2) +
  scale_y_continuous(name = "Vote share",labels = scales::percent) +
  labs(x = "Number of registered voters") +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90,hjust = 1,vjust = .5))

ggsave(here("out/figures", "profcat4_boxplots.pdf"), width = 7, height = 6)
```



```{r}
# after the imputations we decide on the data that is used for modelling
mun2model <- data.frame(
  ID_MUN = mun_elec2census$ID_MUN,
  REGISTERED = rowSums(as.matrix(VOTE_IMP)),
  REGISTERED_G = Reduce("*", lapply(VOTE_IMP, as.numeric)),
  POP_DENSITY = mun_elec2census$POPULATION / mun_elec2census$AREA)
mun2model[["VOTE"]] <- as.matrix(VOTE_IMP)/mun2model$REGISTERED
mun2model[["PROFCAT"]] <- as.matrix(PROFCAT_IMP)/rowSums(PROFCAT_IMP)
```


# Understanding "linear" changes in compositional variables

Here illustrate how compositional variables change using based on the composition of semiprofessional categories in Paris.
In the next section we will show how these changes affect the dependent variable on a model.
Below we have the observed composition for the Paris municipality.

```{r}
paris_id <- "75056"
paris <- mun2model[mun2model$ID_MUN == paris_id,,drop = FALSE]
paris$PROFCAT
```

In the following two subsections take this point of departure and add a sequence of linear increments, where linearity is understood with respect to the geometry of the simplex.
It should be evident that a linear increment of a multivariate vector is defined by a direction and a step size $h=0.1$.
Since we normalized the direction to unit length $h$ reflecets the Aitchison distance between two sequential points.

## Changing in direction of first vertex

```{r}
paris_pcseq1 <- CoDa_path(
  comp_direc = c(2,1,1,1),
  comp_from = paris$PROFCAT,
  add_opposite = TRUE,
  step_size = .1) # take the same step size as before
```

Here we consider the direction that points from the original composition to directly to the first vertex of the simplex.
For our example the first vertex identifies the share of  workers.
Moving along this direction has the special property that the subcomposition that excludes the first element remains constant after closure.
This becomes evident when looking at the two ternary diagrams below, where the first shows the subcomposition that excludes "Other" and the second the one that excludes "Upper".
The composition observed for Paris is shown as a red cross.

```{r}
#| fig-show: hold
#| message: false
#| fig-pos: h
opar <- par(mfrow = c(1,2),oma = c(0,0,0,0))
plot.acomp(paris_pcseq1[,-4])
plot.acomp(paris_pcseq1["0",-4, drop = FALSE], col = "red", add = TRUE, pch = 3, cex = 2)

plot.acomp(paris_pcseq1[,-1])
plot.acomp(paris_pcseq1["0",-1, drop = FALSE], col = "red", add = TRUE, pch = 3, cex = 2)

save_baseplot(pdf, here("out/figures/","Xe_change_ternary.pdf"), width = 7, height = 4)
par(opar)
```
Both graphics above make clear that the ratios between all components except the first stay constant.
This also explains why the path in the left ternary plot appears linear in euclidean sense.
The same changes can be visualized in a stacked bar-plot, where the ratio of bar heights for the remains constant except when "Upper" is involved.
Here we only show changes for the steps defined by $h = -50,...,50$.

```{r}
#| fig-show: hold
names(paris_pcseq1) <- colnames(PROFCAT)
window <- as.character(seq(-40,40,by = 2))
barplot(acomp(paris_pcseq1[window,,drop=FALSE]))
save_baseplot(pdf, here("out/figures","Xe_change_barplot.pdf"))
```

Another way to look at the changing composition is to present the changes to all components as a function of the share of "Upper".
In this graphic we additionally display the empirical distribution of the share of "Upper" over all municipalities.
The vertical line intersects the other at the observed composition for Paris, showing that Paris is an outlier in the "Upper" dimension.

```{r}
#| fig-show: hold
paris_pcseq1_gg <- data.frame(paris_pcseq1)
colnames(paris_pcseq1_gg) <- paste0("PC", 1:4)
ggplot(paris_pcseq1_gg) +
  geom_vline(xintercept = paris$PROFCAT[[1]]) +
  geom_line(aes(x = PC1, y = PC1, col = "1", lty = "1"), lwd = .51) +
  geom_line(aes(x = PC1, y = PC2, col = "2", lty = "2"), lwd = .51) +
  geom_line(aes(x = PC1, y = PC3, col = "3", lty = "3"), lwd = .51) +
  geom_line(aes(x = PC1, y = PC4, col = "4", lty = "4"), lwd = .51) +
  geom_hline(yintercept = 1, col = "black") +
  geom_boxplot(
    data = data.frame(PC1 = mun2model$PROFCAT[,1]),
    mapping = aes(x = PC1, y = 1 + .0625),
    varwidth = TRUE,
    size = .5,
    col = "red",
    alpha = .25,
    width = .05) +
  scale_x_continuous(
    labels = scales::percent,
    sec.axis = dup_axis(name= "Boxplot of % in professional category: Upper")) +
  scale_y_continuous(
    labels = scales::percent,breaks = seq(0,1,.25)) +
  scale_color_manual(
    breaks = c("1","2", "3", "4"),
    values = c("Red", "Orange", "Dark Blue", "Yellow"),
    name = "Professional\ncategory",
    labels = colnames(PROFCAT)) +
  scale_linetype_manual(
    breaks = c("1","2", "3", "4"),
    values = 1:4,
    name = "Professional\ncategory",
    labels = colnames(PROFCAT)) +
  labs(x = "% in professional category: Upper",
       y = "% in professional category") +
  coord_equal() +
  theme_bw()

ggsave(here("out/figures/Xe_change_scatter_with_details.pdf"), height = 6, width = 6)
```


```{r}
#| include: false
paris_pcseq1_gg <- data.frame(paris_pcseq1)
colnames(paris_pcseq1_gg) <- paste0("PC", 1:4)
ggplot(paris_pcseq1_gg) +
  geom_vline(xintercept = paris$PROFCAT[[1]]) +
  geom_line(aes(x = PC1, y = PC1, col = "1", lty = "1"), lwd = .51) +
  geom_line(aes(x = PC1, y = PC2, col = "2", lty = "2"), lwd = .51) +
  geom_line(aes(x = PC1, y = PC3, col = "3", lty = "3"), lwd = .51) +
  geom_line(aes(x = PC1, y = PC4, col = "4", lty = "4"), lwd = .51) +
  geom_hline(yintercept = 1, col = "black") +
  geom_boxplot(
    data = data.frame(PC1 = mun2model$PROFCAT[,1]),
    mapping = aes(x = PC1, y = 1 + .0625),
    varwidth = TRUE,
    size = .5,
    col = "red",
    alpha = .25,
    width = .05) +
  scale_x_continuous(
    labels = scales::percent) +
  scale_y_continuous(
    labels = scales::percent,breaks = seq(0,1,.25)) +
  scale_color_manual(
    breaks = c("1","2", "3", "4"),
    values = c("Red", "Orange", "Dark Blue", "Yellow"),
    name = "Professional\ncategory",
    labels = colnames(PROFCAT)) +
  scale_linetype_manual(
    breaks = c("1","2", "3", "4"),
    values = 1:4,
    name = "Professional\ncategory",
    labels = colnames(PROFCAT)) +
  labs(x = "% in professional category: Upper",
       y = "% in professional category") +
  coord_equal() +
  theme_bw()

ggsave(here("out/figures/Xe_change_scatter.pdf"), height = 6, width = 6)
```



## Changing in a general direction

The same procedure can be replaced for a general direction.
Here we chose a path for which the share of "Upper" passes through the whole interval $(0,1)$, because we want to show graphics that are comparable to the previous ones.

```{r}
dir_gen <- c(.1,.5,.25,.15)
paris_pcseq2 <- CoDa_path(
  comp_direc = dir_gen,
  comp_from = paris$PROFCAT,
  add_opposite = TRUE,
  step_size = attr(paris_pcseq1,"step_size")) # take the same step size as before
```

An alternative direction is the one that points from the observed point for Paris to the origin of the simplex.
The two ternary diagrams below show a path generated along this direction, where the red cross is the empirical composition for Paris and the blue star the origin.

```{r}
#| fig-show: "hold"
opar <- par(mfrow = c(1,2),oma = c(0,0,0,0))
plot.acomp(paris_pcseq2[,-4])
plot.acomp(paris_pcseq2["0",-4, drop = FALSE], col = "red", add = TRUE, pch = 3, cex = 2)

plot.acomp(paris_pcseq2[,-1])
plot.acomp(paris_pcseq2["0",-1, drop = FALSE], col = "red", add = TRUE, pch = 3, cex = 2)

save_baseplot(pdf, here("out/figures/","Xu_change_ternary.pdf"), width = 7, height = 4)
par(opar)
```

The simplex-linear path generated by this direction looks more complex because it is non-linear in euclidean sense.
For this path we also the ratios of the other components are no-longer constant and the changes are generally also not monotonic.
This becomes evident when looking the shares of "Other" and "Retired" that peak close to the center of our variation and decline towards both edges.


```{r}
names(paris_pcseq2) <- colnames(PROFCAT)
window <- as.character(seq(-80,80,by = 4))
barplot(acomp(paris_pcseq2[window,,drop=FALSE]))
save_baseplot(pdf, here("out/figures/","Xu_change_barplot.pdf"))
```

When looking at the functional representation of this linear path we clearly see that the shares for each professional category cross at the origin of the 4-dimensional simplex.
The intersection with the black line is again the empirical composition of Paris.

```{r}
#| fig-show: hold
paris_pcseq2_gg <- data.frame(paris_pcseq2)
colnames(paris_pcseq2_gg) <- paste0("PC", 1:4)
ggplot(paris_pcseq2_gg) +
  geom_vline(xintercept = paris$PROFCAT[[1]]) +
  geom_vline(xintercept = 1/4, col = "grey55") +
  geom_line(aes(x = PC1, y = PC1, col = "1", lty = "1"), lwd = .51) +
  geom_line(aes(x = PC1, y = PC2, col = "2", lty = "2"), lwd = .51) +
  geom_line(aes(x = PC1, y = PC3, col = "3", lty = "3"), lwd = .51) +
  geom_line(aes(x = PC1, y = PC4, col = "4", lty = "4"), lwd = .51) +
  geom_hline(yintercept = 1, col = "black") +
  geom_boxplot(
    data = data.frame(PC1 = mun2model$PROFCAT[,1]),
    mapping = aes(x = PC1, y = 1 + .0625),
    varwidth = TRUE,
    size = .5,
    col = "red",
    alpha = .25,
    width = .05) +
  scale_x_continuous(
    labels = scales::percent,
    sec.axis = dup_axis(name= "Boxplot of % in professional category: Upper")) +
  scale_y_continuous(
    labels = scales::percent,breaks = seq(0,1,.25)) +
  scale_color_manual(
    breaks = c("1","2", "3", "4"),
    values = c("Red", "Orange", "Dark Blue", "Yellow"),
    name = "Professional\ncategory",
    labels = colnames(PROFCAT)) +
  scale_linetype_manual(
    breaks = c("1","2", "3", "4"),
    values = 1:4,
    name = "Professional\ncategory",
    labels = colnames(PROFCAT)) +
  labs(x = "% in professional category: Upper",
       y = "% in professional category") +
  coord_equal() +
  theme_bw()

ggsave(here("out/figures/Xu_change_scatter_with_details.pdf"), height = 6, width = 6)
```

```{r}
#| include: false
paris_pcseq2_gg <- data.frame(paris_pcseq2)
colnames(paris_pcseq2_gg) <- paste0("PC", 1:4)
ggplot(paris_pcseq2_gg) +
  geom_vline(xintercept = paris$PROFCAT[[1]]) +
  geom_vline(xintercept = 1/4, col = "grey55") +
  geom_line(aes(x = PC1, y = PC1, col = "1", lty = "1"), lwd = .51) +
  geom_line(aes(x = PC1, y = PC2, col = "2", lty = "2"), lwd = .51) +
  geom_line(aes(x = PC1, y = PC3, col = "3", lty = "3"), lwd = .51) +
  geom_line(aes(x = PC1, y = PC4, col = "4", lty = "4"), lwd = .51) +
  geom_hline(yintercept = 1, col = "black") +
  geom_boxplot(
    data = data.frame(PC1 = mun2model$PROFCAT[,1]),
    mapping = aes(x = PC1, y = 1 + .0625),
    varwidth = TRUE,
    size = .5,
    col = "red",
    alpha = .25,
    width = .05) +
  scale_x_continuous(labels = scales::percent) +
  scale_y_continuous(
    labels = scales::percent,breaks = seq(0,1,.25)) +
  scale_color_manual(
    breaks = c("1","2", "3", "4"),
    values = c("Red", "Orange", "Dark Blue", "Yellow"),
    name = "Professional\ncategory",
    labels = colnames(PROFCAT)) +
  scale_linetype_manual(
    breaks = c("1","2", "3", "4"),
    values = 1:4,
    name = "Professional\ncategory",
    labels = colnames(PROFCAT)) +
  labs(x = "% in professional category: Upper",
       y = "% in professional category") +
  coord_equal() +
  theme_bw()

ggsave(here("out/figures/Xu_change_scatter.pdf"), height = 6, width = 6)
```



## Changing in direction of the origin

In the case where the direction and the starting point coincides the path will pass through the origin of the simplex.

```{r}
paris_pcseq3 <- CoDa_path(
  comp_direc = paris$PROFCAT,
  comp_from = paris$PROFCAT,
  add_opposite = TRUE,
  step_size = attr(paris_pcseq1,"step_size")) # take the same step size as before
```

The two ternary diagrams below show a path generated along this direction, where the red cross is the empirical composition for Paris and the blue star the origin.

```{r}
#| fig-show: "hold"
opar <- par(mfrow = c(1,2),oma = c(0,0,0,0))
plot.acomp(paris_pcseq3[,-4])
plot.acomp(paris_pcseq3["0",-4, drop = FALSE], col = "red", add = TRUE, pch = 3, cex = 2)
plot.acomp(c(1,1,1), col = "blue", add = TRUE, pch = 8, cex = 2)

plot.acomp(paris_pcseq3[,-1])
plot.acomp(paris_pcseq3["0",-1, drop = FALSE], col = "red", add = TRUE, pch = 3, cex = 2)
plot.acomp(c(1,1,1), col = "blue", add = TRUE, pch = 8, cex = 2)
par(opar)
```

The simplex-linear path generated by this direction looks more complex because it is non-linear in euclidean sense.
For this path we also the ratios of the other components are no-longer constant and the changes are generally also not monotonic.
This becomes evident when looking the shares of "Other" and "Retired" that peak close to the center of our variation and decline towards both edges.


```{r}
names(paris_pcseq3) <- colnames(PROFCAT)
window <- as.character(seq(-40,40,by = 2))
barplot(acomp(paris_pcseq3[window,,drop=FALSE]))
```

When looking at the functional representation of this linear path we clearly see that the shares for each professional category cross at the origin of the 4-dimensional simplex.
The intersection with the black line is again the empirical composition of Paris.

```{r}
#| fig-show: hold
paris_pcseq3_gg <- data.frame(paris_pcseq3)
colnames(paris_pcseq3_gg) <- paste0("PC", 1:4)
ggplot(paris_pcseq3_gg) +
  geom_vline(xintercept = paris$PROFCAT[[1]]) +
  geom_vline(xintercept = 1/4, col = "grey55") +
  geom_line(aes(x = PC1, y = PC1, col = "1", lty = "1"), lwd = .51) +
  geom_line(aes(x = PC1, y = PC2, col = "2", lty = "2"), lwd = .51) +
  geom_line(aes(x = PC1, y = PC3, col = "3", lty = "3"), lwd = .51) +
  geom_line(aes(x = PC1, y = PC4, col = "4", lty = "4"), lwd = .51) +
  geom_hline(yintercept = 1, col = "black") +
  geom_boxplot(
    data = data.frame(PC1 = mun2model$PROFCAT[,1]),
    mapping = aes(x = PC1, y = 1 + .0625),
    varwidth = TRUE,
    size = .5,
    col = "red",
    alpha = .25,
    width = .05) +
  scale_x_continuous(
    labels = scales::percent,
    sec.axis = dup_axis(name= "Boxplot of % in professional category: Upper")) +
  scale_y_continuous(
    labels = scales::percent,breaks = seq(0,1,.25)) +
  scale_color_manual(
    breaks = c("1","2", "3", "4"),
    values = c("Red", "Orange", "Dark Blue", "Yellow"),
    name = "Professional\ncategory",
    labels = colnames(PROFCAT)) +
  scale_linetype_manual(
    breaks = c("1","2", "3", "4"),
    values = 1:4,
    name = "Professional\ncategory",
    labels = colnames(PROFCAT)) +
  labs(x = "% in professional category: Upper",
       y = "% in professional category") +
  coord_equal() +
  theme_bw()
```

# Y-scalar model interpretations


In this section we look at a model that explains a transformation of the turnout rate, which we treat as a real variables.


```{r}
mun2model$TURNOUT <- 1 - mun2model$VOTE[,6]
TURNOUT_model <- lmCoDa(
  TURNOUT ~  log(POP_DENSITY) + ilr(PROFCAT) + 1,
  data = mun2model,
  weights = REGISTERED)

summary(TURNOUT_model)
```

The analysis of variance is given by

```{r}
aov <- anova(TURNOUT_model)
aov$`Sum Sq` <- round(aov$`Sum Sq`, 2)
aov$`Mean Sq` <- round(aov$`Mean Sq`, 2)
aov$`F value` <- round(aov$`F value`, 2)

kable(aov, caption = "Analysis of variance table for the X-compositional model") |> kable_classic()
kable(aov, caption = "Analysis of variance table for the X-compositional model", label = "aov_TURNOUT",format = "latex", booktabs = TRUE) |> 
  kable_styling(latex_options = "hold_position") |> 
  save_kable(file = here("out/tables/aov_TURNOUT.tex"))
```



## Interpreting the impact of scalar X

Constant marginal effects.

## Interpreting the impact of compositional X

Constant semi-elasticities.

### Semi-elasticites

In this model the clr transformed coefficients are equal to the semi-elasticity of the shares.

```{r}
#| fig-show: hold
#| warning: false
clr_confint <- confint(TURNOUT_model, "PROFCAT")

ggplot(clr_confint) +
  theme_bw() +
  coord_flip() +
  geom_hline(yintercept = 0) +
  geom_segment(aes(x=X, xend=X, y=0, yend=EST, col = X)) +
  geom_point(aes(x=X, y = EST, col = X)) +
  geom_point(aes(x=X, y = `2.5 %`, col = X), pch = "[", stroke = 3) +
  geom_point(aes(x=X, y = `97.5 %`, col = X), pch = "]", stroke = 3) +
  labs(y = "semi-elasticities values", x = NULL) +
  theme(legend.position = "none")

ggsave(here("out/figures", "yscalar_elasticity_profcat.pdf"), height = 2, width = 7)
```


### Variation Table

The table below illustrates how the dependent variable TURNOUT would react to a change in the composition of the professional categories, where we focus on the municipality of Paris.

```{r}
paris_num <- which(mun2model$ID_MUN == paris_id)
paris_varTab <- cbind(
  VariationTable(TURNOUT_model,Xvar = "PROFCAT", Xdir = "Upper", inc_size = .1, obs = paris_num),
  VariationTable(TURNOUT_model,Xvar = "PROFCAT", Xdir = dir_gen, inc_size = .1, obs = paris_num))
row.names(paris_varTab)[4] <- "Variation in % points"
paris_varTab[4,] <- paris_varTab[5,] * 100
paris_varTab <- paris_varTab[-5,]

tab_atr <- VariationTable(TURNOUT_model,Xvar = "PROFCAT", Xdir = "Upper", inc_size = .1, obs = paris_num)
tab_atr <- attributes(tab_atr)
colnames(paris_varTab) <- c("Direction to vertex", "General direction")
format_VarTab(paris_varTab, 3,digitsP = 3, digitsPP =  3) |> 
  kable(caption = "Variation of the turnout when changing  PC in different directions", digits = 4, booktabs = TRUE) |> 
  add_footnote(sprintf("h = %s, alpha=%s%%", tab_atr$inc_size, round(100*tab_atr$inc_rate,2))) 
```


```{r}
#| include: false
format_VarTab(paris_varTab, 3,digitsP = 2, digitsPP =  2) |> 
  kable(caption = "Impacts of change in PC on the turnout", digits = 4, booktabs = TRUE,
        format = "latex",label = "VarTab_TURNOUT_XeXu_change", linesep = "") |> 
  # add_footnote(sprintf("h = %s, alpha=%s%%", tab_atr$inc_size, round(100*tab_atr$inc_rate,2)))  |> 
  kable_styling(latex_options = "hold_position") |> 
  save_kable(here("out/tables/VarTab_TURNOUT_XeXu_change.tex"))
```


### Variation scenario

We now evaluate how the two scenarios of changes in the socio-professional composition of Paris would impact the vote shares of each candidate.
We see that all scenarios pass through the observed composition for Paris and lead to a predicted turnout of about $72.9\%$.
In the hypothetical scenario where Paris has equal population in each professional category the turnout is predicted to drop to about $67\%$.


```{r}
#| fig-show: hold
#| warning: false

# first scenario data
paris_pred1 <- paris[rep(1,nrow(paris_pcseq1)),]
paris_pred1$PROFCAT <- as.matrix(paris_pcseq1)
paris_pred1$VOTE <- NULL
paris_pred1$PRED_TURNOUT <- predict(TURNOUT_model, newdata = paris_pred1) 
paris_pred1$H_SEQ <- row.names(paris_pred1) <- row.names(paris_pcseq1)
paris_pred1$F_SHARE <- paris_pred1$PROFCAT[,"Upper"]

paris_pred1_gg <- melt(
  data = data.table(paris_pred1),
  id.vars = c("H_SEQ","F_SHARE","PRED_TURNOUT"),
  measure.vars = paste0("PROFCAT.", colnames(PROFCAT)))

# second scenario data
paris_pred2 <- paris[rep(1,nrow(paris_pcseq2)),]
paris_pred2$PROFCAT <- as.matrix(paris_pcseq2)
paris_pred2$VOTE <- NULL
paris_pred2$PRED_TURNOUT <- predict(TURNOUT_model, newdata = paris_pred2) 
paris_pred2$H_SEQ <- row.names(paris_pred2) <- c(row.names(paris_pcseq2))
paris_pred2$F_SHARE <- paris_pred2$PROFCAT[,"Upper"]

paris_pred2_gg <- melt(
  data = data.table(paris_pred2),
  id.vars = c("H_SEQ","F_SHARE","PRED_TURNOUT"),
  measure.vars = paste0("PROFCAT.", colnames(PROFCAT)))

# third scenario data
paris_pred3 <- paris[rep(1,nrow(paris_pcseq3) + 1),]
paris_pred3$PROFCAT <- rbind(as.matrix(paris_pcseq3),rep(.25,4)) # add the origin
paris_pred3$VOTE <- NULL
paris_pred3$PRED_TURNOUT <- predict(TURNOUT_model, newdata = paris_pred3) 
paris_pred3$H_SEQ <- row.names(paris_pred3) <- c(row.names(paris_pcseq3),"101")
paris_pred3$F_SHARE <- paris_pred3$PROFCAT[,"Upper"]

paris_pred3_gg <- melt(
  data = data.table(paris_pred3),
  id.vars = c("H_SEQ","F_SHARE", "PRED_TURNOUT"),
  measure.vars = paste0("PROFCAT.", colnames(PROFCAT)))


paris_pred_gg <- rbind(
  cbind("DIR" = "Direction to vertex", paris_pred1_gg),
  cbind("DIR" = "General direction", paris_pred2_gg),
  cbind("DIR" = "Origin direction", paris_pred3_gg))
paris_pred_gg[,variable := str_remove(variable,"PROFCAT.")]
paris_pred_gg[,variable := factor(variable,colnames(PROFCAT))]

hline <- data.frame(
  INT = c(paris_pred1[c("0","0","0"), "PRED_TURNOUT"],paris_pred3["101", "PRED_TURNOUT"]),
  DIR = c("Direction to vertex","General direction", "Origin direction", "Origin direction"),
  LAB = c("(Paris)", "(Paris)", "(Paris)", "(origin)"),
  YYY = c(.85),
  JJJ = c(-.5,-.5,-.5, 1.5))

ggplot(paris_pred_gg) +
  geom_vline(aes(xintercept = INT), data = hline) +
  geom_text(aes(x = INT, y = YYY, label = LAB, vjust = JJJ), data =  hline) +
  geom_line(aes(y = value, x = PRED_TURNOUT, col =variable, lty = variable)) +
  scale_y_continuous(breaks = seq(0,10)/10,labels = scales::percent) +
  scale_x_continuous(labels = scales::percent,sec.axis = dup_axis(name = NULL), limits = c(.5,.9)) +
  coord_flip() +
  theme_bw() +
  labs(y = "share in professional category", x = "predicted turnout",
       col = "Professional\ncategory", lty = "Professional\ncategory") +
  facet_wrap("DIR", ncol = 1, scales = "free_x")
```

Focusing on the first two scenarios the graph becomes

```{r}
#| warning: false
ggplot(paris_pred_gg[DIR != "Origin direction",]) +
  geom_vline(aes(xintercept = INT), data = hline[1:2,]) +
  geom_text(aes(x = INT, y = YYY, label = LAB, vjust = JJJ), data =  hline[1:2,]) +
  geom_line(aes(y = value, x = PRED_TURNOUT, col =variable, lty = variable)) +
  scale_y_continuous(breaks = seq(0,10)/10,labels = scales::percent) +
  scale_x_continuous(labels = scales::percent,sec.axis = dup_axis(name = NULL), limits = c(.5,.9)) +
  theme_bw() +
  coord_flip() +
  labs(y = "share in professional category", x = "predicted turnout",
       col = "Professional\ncategory", lty = "Professional\ncategory") +
  facet_wrap("DIR", ncol = 1, scales = "free_x")
```

An alternative and maybe simpler way to show the same information is to look simultaneously at the changes of the depndents and independent variables as a function of $h$.

```{r}
paris_pred_gg2 <- copy(paris_pred_gg[DIR != "Origin direction",])
paris_pred_gg2[, COMPO := "Change in X"]

paris_pred_gg3 <- copy(paris_pred_gg2[variable == "Upper",])
paris_pred_gg3[, COMPO := "Change in Y"]
paris_pred_gg3[, variable := NA]
paris_pred_gg3[,value := PRED_TURNOUT]

paris_pred_ggX <- rbind(paris_pred_gg2, paris_pred_gg3)
paris_pred_ggX[, COMPO := factor(COMPO, c("Change in Y", "Change in X"))]
paris_pred_ggX[,H_SEQ := as.integer(H_SEQ)]
rm(paris_pred_gg2, paris_pred_gg3)

ggplot(paris_pred_ggX[-30 <= H_SEQ & H_SEQ <= 30]) +
  geom_vline(xintercept = 0) +
  # geom_text(aes(x = INT, y = YYY, label = LAB, vjust = JJJ), data =  hline[1:2,]) +
  geom_line(aes(y = value, x = H_SEQ/10, col =variable, lty = variable)) +
  scale_y_continuous(breaks = seq(0,10)/10,labels = scales::percent) +
  scale_colour_manual(values = scales::hue_pal()(4), na.value = "#000000", breaks = levels(paris_pred_ggX$variable))  + 
  scale_linetype_manual(values = 1:4, na.value = 1, , breaks = levels(paris_pred_ggX$variable))  + 
  # scale_x_continuous(labels = scales::percent,sec.axis = dup_axis(name = NULL), limits = c(.5,.9)) +
  theme_bw() +
  labs(y = "share in PC (bottom) and predicted turnout (top)", x = "value of h",
       col = "Professional\ncategory", lty = "Professional\ncategory") +
  facet_grid(COMPO ~ DIR, scales = "free")

ggsave(here("out/figures/x_compo_variation_scatter.pdf"), height = 5, width = 7)
```



# Y-compositional model interpretations

Here we look at the case of a Y-compositional model that explains the full composition of votes.

```{r}
VOTE_model <- lmCoDa(
  ilr(VOTE) ~  log(POP_DENSITY) + ilr(PROFCAT),
  data = mun2model)
summary(VOTE_model)
```


```{r}
aov <- anova(VOTE_model)
aov$`approx F` <- round(aov$`approx F`)
aov$Pillai <- round(aov$Pillai, 3)

kable(aov, caption = "Analysis of variance table for the y-compositional model") |> kable_classic()
kable(aov, caption = "Analysis of variance table for the y-compositional model", label = "aov_VOTE", format = "latex", booktabs = TRUE) |> 
  kable_styling(latex_options = "hold_position") |> 
  save_kable(file = here("out/tables/aov_VOTE.tex"))
```



## Interpreting the impact of a scalar X


### Semi-elasticities diffrence

The clr coefficients correspond to a difference from a mean elasticity.

```{r}
#| fig-show: hold
#| warning: false
flevels <- c("-Mean semi elasticity", rev(rename_elec))
clr_confint <- confint(VOTE_model, "log(POP_DENSITY)")
clr_confint$Y <- factor(clr_confint$Y, flevels)
clr_confintB <- clr_confint[1,]
clr_confintB$Y <- factor("-Mean semi elasticity", levels = flevels)
clr_confintB[,3:6] <- NA
clr_T <- coef(VOTE_model, "clr")
ME <- as(fitted(VOTE_model, "simplex"),"matrix") %*% t(clr_T[-1,])
ME <- melt(data.table(ME), variable.name = "X", value.name = "EST")
ME[,Y := factor("-Mean semi elasticity", levels = flevels)]

ggplot(rbind(clr_confint,clr_confintB)) +
  theme_bw() +
  coord_flip() +
  geom_hline(yintercept = 0) +
  geom_segment(aes(x=Y, xend=Y, y=0, yend=EST, col = Y)) +
  geom_point(aes(x=Y, y = EST, col = Y)) +
  geom_point(aes(x=Y, y = `2.5 %`, col = Y), pch = "[", stroke = 3) +
  geom_point(aes(x=Y, y = `97.5 %`, col = Y), pch = "]", stroke = 3) +
  geom_violin(aes(y = EST, x = Y),data = ME[X=="log(POP_DENSITY)",]) +
  labs(y = "clr parameter values & confidence intervals\ndistribution of negative mean semi elasticity", x = NULL) +
  theme(legend.position = "none")

ggsave(here("out/figures", "clr_b_popdens_with_details.pdf"), height = 2.5, width = 7)
```

```{r}
#| include: false
ggplot(rbind(clr_confint,clr_confintB)) +
  theme_bw() +
  coord_flip() +
  geom_hline(yintercept = 0) +
  geom_segment(aes(x=Y, xend=Y, y=0, yend=EST, col = Y)) +
  geom_point(aes(x=Y, y = EST, col = Y)) +
  geom_point(aes(x=Y, y = `2.5 %`, col = Y), pch = "[", stroke = 3) +
  geom_point(aes(x=Y, y = `97.5 %`, col = Y), pch = "]", stroke = 3) +
  geom_violin(aes(y = EST, x = Y),data = ME[X=="log(POP_DENSITY)",]) +
  labs(y = "clr parameter values", x = NULL) +
  theme(legend.position = "none")

ggsave(here("out/figures", "clr_b_popdens.pdf"), height = 2.5, width = 7)
```



We can use them to construct differences between the elasticities of two components of the dependent shares with respect to the same variable.

```{r}
#| fig-show: hold
#| warning: false
clr_confint <- confint(VOTE_model, "log(POP_DENSITY)",y_ref = 1)
clr_confint$Y <- factor(clr_confint$Y, flevels)
clr_confintB <- clr_confint[1,]
clr_confintB[,3:6] <- NA

ggplot(rbind(clr_confint,clr_confintB)) +
  theme_bw() +
  coord_flip() +
  geom_hline(yintercept = 0) +
  geom_segment(aes(x=Y, xend=Y, y=0, yend=DIFF, col = Y)) +
  geom_point(aes(x=Y, y = DIFF, col = Y)) +
  geom_point(aes(x=Y, y = `2.5 %`, col = Y), pch = "[", stroke = 3) +
  geom_point(aes(x=Y, y = `97.5 %`, col = Y), pch = "]", stroke = 3) +
  labs(y = "semi-elasticity differences & confidence intervals\n(reference is the share of Macron)", x = NULL) +
  theme(legend.position = "none")

ggsave(here("out/figures", "SE_diff_popdens_with_details.pdf"), height = 2, width = 7)
```

```{r}
#| include: false
ggplot(rbind(clr_confint,clr_confintB)) +
  theme_bw() +
  coord_flip() +
  geom_hline(yintercept = 0) +
  geom_segment(aes(x=Y, xend=Y, y=0, yend=DIFF, col = Y)) +
  geom_point(aes(x=Y, y = DIFF, col = Y)) +
  geom_point(aes(x=Y, y = `2.5 %`, col = Y), pch = "[", stroke = 3) +
  geom_point(aes(x=Y, y = `97.5 %`, col = Y), pch = "]", stroke = 3) +
  labs(y = "semi-elasticity differences", x = NULL) +
  theme(legend.position = "none")

ggsave(here("out/figures", "SE_diff_popdens.pdf"), height = 2, width = 7)
```


### Variation table

We can use Taylor approximations for to evaluate how the voting behavior reacts to a to a small change in the overall number of registered voters.
Here we use $\text{log(POP_DENSITY)} + .1$ which means that population density increases by about 10%.

```{r}
paris_num <- which(mun2model$ID_MUN == paris_id)
paris_varTab <- VariationTable(VOTE_model, "log(POP_DENSITY)",inc_size = .1, obs = paris_num, Ytotal = mun2model$REGISTERED[paris_num])

format_VarTab(paris_varTab, 4, 0, 2, 2) |> 
  kable(caption = "Increase of the population density by 10%", digits = 4, booktabs = TRUE)
```


```{r}
format_VarTab(paris_varTab, 4, 0, 2, 2) |> 
  kable(caption = "Increase of the population density by 10\\%", digits = 4, booktabs = TRUE,
        format = "latex", label = "VarTab_VOTE_logPDENS_change", linesep = "") |> 
  kable_styling(latex_options = "hold_position") |> 
  save_kable(here("out/tables/VarTab_VOTE_logPDENS_change.tex"))
```


It is easy to verify that the variations in % points and units compensate each other.

```{r}
round(rowSums(paris_varTab),10)
```


### Variation scenarios

In this scenario we suppose that the number of population density changes on a grid that is regular in logs.
Even for the extreme changes such as a tenfold increase of the population or reduction to one tenth would not lead to a lot of variation.
When the population of Paris is shrunk one $0.1\%$ of its original size we see considerable differences.

```{r}
#| fig-show: hold
paris_size_scenario <- paris[rep(1,101),]
paris_size_scenario$POP_DENSITY <- paris_size_scenario$POP_DENSITY * exp(seq(-log(1000),log(10),length.out = 101))
paris_size_scenario$VOTE <- as(predict(VOTE_model,space = "simplex", newdata = paris_size_scenario), "matrix")
colnames(paris_size_scenario$VOTE) <- colnames(VOTE)

paris_size_scenario_gg <- melt(
  data = data.table(paris_size_scenario),
  id.vars = "POP_DENSITY",
  measure.vars = make.names(paste0("VOTE.",colnames(VOTE))))


unmake_votenames <- structure(colnames(VOTE), names = make.names(paste0("VOTE.",colnames(VOTE))))
paris_size_scenario_gg[,variable := factor(unmake_votenames[variable],unmake_votenames)]
ggplot(paris_size_scenario_gg) +
  geom_vline(xintercept = paris$POP_DENSITY) +
  geom_line(aes(x = POP_DENSITY, y = value, col = variable, lty = variable)) +
  scale_x_continuous(trans = "log10") +
  scale_y_continuous(labels = scales::percent) +
  labs(y = "vote share", x = "population density", col = "candidate", lty = "candidate") +
  theme_bw()

ggsave(here("out/figures","y_compo_variation_scatter.pdf"), height = 5, width = 7)
```


## Interpreting the impact of a X-compositional variable

### Elasticities difference

For X-compositional variables the clr coefficients also correspond to differences in mean elasticities, where these means are computed for each component of $X$ over all dependent shares.

```{r}
#| fig-show: hold
#| warning: false
clr_confint <- confint(VOTE_model, "PROFCAT")
clr_confint$Y <- factor(clr_confint$Y,levels = flevels)
clr_confint_all <- clr_confint
clr_confint_all$Y <- factor("-Mean elasticity", flevels)
clr_confint_all$SD <- clr_confint_all$EST
clr_confint_all$EST <- NA
clr_confint_all$`2.5 %` <- NA
clr_confint_all$`97.5 %` <- NA
clr_confint_all <- unique(clr_confint_all)
levels(ME$Y)[1] <- "-Mean elasticity"

ggplot(rbind(clr_confint,clr_confint_all)) +
  theme_bw() +
  coord_flip() +
  geom_hline(yintercept = 0) +
  geom_segment(aes(x=Y, xend=Y, y=0, yend=EST, col = Y)) +
  geom_point(aes(x=Y, y = EST, col = Y)) +
  geom_point(aes(x=Y, y = `2.5 %`, col = Y), pch = "[", stroke = 3) +
  geom_point(aes(x=Y, y = `97.5 %`, col = Y), pch = "]", stroke = 3) +
  geom_violin(aes(y = EST, x = Y),data = ME[X!="log(POP_DENSITY)"]) +
  facet_wrap("X") +
  labs(y = "parameter values & confidence intervals\ndistribution of negative mean elasticity", x = NULL) +
  theme(legend.position = "none")

ggsave(here("out/figures", "clr_B_profcat_with_details.pdf"), height = 4, width = 7)
```

```{r}
#| include: false
ggplot(rbind(clr_confint,clr_confint_all)) +
  theme_bw() +
  coord_flip() +
  geom_hline(yintercept = 0) +
  geom_segment(aes(x=Y, xend=Y, y=0, yend=EST, col = Y)) +
  geom_point(aes(x=Y, y = EST, col = Y)) +
  geom_point(aes(x=Y, y = `2.5 %`, col = Y), pch = "[", stroke = 3) +
  geom_point(aes(x=Y, y = `97.5 %`, col = Y), pch = "]", stroke = 3) +
  geom_violin(aes(y = EST, x = Y),data = ME[X!="log(POP_DENSITY)"]) +
  facet_wrap("X") +
  labs(y = "parameter values", x = NULL) +
  theme(legend.position = "none")

ggsave(here("out/figures", "clr_B_profcat.pdf"), height = 4, width = 7)
```



```{r}
#| fig-show: hold
#| warning: false
clr_confint <- confint(VOTE_model, "PROFCAT",y_ref = 1)
clr_confint$Y <- factor(clr_confint$Y,levels = flevels)
ggplot(clr_confint) +
  theme_bw() +
  coord_flip() +
  geom_hline(yintercept = 0) +
  geom_segment(aes(x=Y, xend=Y, y=0, yend=DIFF, col = Y)) +
  geom_point(aes(x=Y, y = DIFF, col = Y)) +
  geom_point(aes(x=Y, y = `2.5 %`, col = Y), pch = "[", stroke = 3) +
  geom_point(aes(x=Y, y = `97.5 %`, col = Y), pch = "]", stroke = 3) +
  facet_wrap("X") +
  labs(y = "elasticity differnces & confidence intervals\n(reference is the share of Macron)", x = NULL) +
  theme(legend.position = "none")

ggsave(here("out/figures", "E_diff_profcat_with_details.pdf"), height = 3.5, width = 7)
```

```{r}
#| include: false
ggplot(clr_confint) +
  theme_bw() +
  coord_flip() +
  geom_hline(yintercept = 0) +
  geom_segment(aes(x=Y, xend=Y, y=0, yend=DIFF, col = Y)) +
  geom_point(aes(x=Y, y = DIFF, col = Y)) +
  geom_point(aes(x=Y, y = `2.5 %`, col = Y), pch = "[", stroke = 3) +
  geom_point(aes(x=Y, y = `97.5 %`, col = Y), pch = "]", stroke = 3) +
  facet_wrap("X") +
  labs(y = "elasticity differnces", x = NULL) +
  theme(legend.position = "none")

ggsave(here("out/figures", "E_diff_profcat.pdf"), height = 3.5, width = 7)
```




### Variation table

Similar to the previous variation Table we  evaluate how the voting behavior reacts to a to a small change in the explanatory composition.
However, since this variable is multivariate we also have to specify the direction of change.
For a change towards the vertex "Upper" we get the following:

```{r}
paris_varTab <- VariationTable(VOTE_model, "PROFCAT", Xdir = "Upper",inc_size = .1, obs = paris_num, Ytotal = mun2model$REGISTERED[paris_num])
tab_atr <- attributes(paris_varTab)
paris_varTab <- format_VarTab(paris_varTab, 3, 0,digitsP = 2,digitsPP = 2)
paris_varTab |> 
  kable(caption = "Change of (PC) in direction of the vertex \"Upper\"", digits = 4, booktabs = TRUE) |> 
    add_footnote(sprintf("h = %s, alpha=%s%%", tab_atr$inc_size, round(100*tab_atr$inc_rate,2)))  
```


```{r}
#| include: false
paris_varTab |> 
  kable(caption = "Change of PC in direction of the vertex \"Upper\"", digits = 4, booktabs = TRUE,
        format = "latex", label = "VarTab_VOTE_Xe_change", linesep = "") |> 
  kable_styling(latex_options = "hold_position") |> 
  # add_footnote(sprintf("h = %s", tab_atr$inc_size))  |> 
  save_kable(here("out/tables/VarTab_VOTE_Xe_change.tex"))
```


For the general direction we get:

```{r}
paris_varTab <- VariationTable(
  VOTE_model,
  Xvar =  "PROFCAT",
  Xdir = dir_gen,
  inc_size = .1,
  obs = paris_num,
  Ytotal = mun2model$REGISTERED[paris_num])

paris_varTab <- format_VarTab(paris_varTab, 3, 0,digitsP = 2,digitsPP = 2)
paris_varTab |> 
  kable(caption = "Change of PC in a general direction", digits = 4, booktabs = TRUE)

```


```{r}
#| include: false
paris_varTab |> 
  kable(caption = "Change in a general direction", digits = 4, booktabs = TRUE ,
      format = "latex", label = "VarTab_VOTE_Xu_change", linesep = "")  |> 
  kable_styling(latex_options = "hold_position") |> 
  save_kable(file = here("out/tables/VarTab_VOTE_Xu_change.tex"))
```


### Variation scenarios

Turning to the changes induced by the variation of the socio-professional composition in Paris.
Here we show the changes in the explanatory composition on top of the changes in the predicted shares.
The graphic below displays the changes as a function of the category "Upper".

```{r}
paris_pred1$VOTE <- as(predict(VOTE_model, space = "simplex", newdata = paris_pred1),"matrix")
paris_pred2$VOTE <- as(predict(VOTE_model, space = "simplex", newdata = paris_pred2),"matrix")
unmake_pc_vote_names <- c(
  structure(paste0("(PC) ", colnames(PROFCAT)), names = paste0("PROFCAT.", colnames(PROFCAT))),
  structure(paste0("(Vote) ", unmake_votenames), names = names(unmake_votenames)))

paris_pred1_gg <- melt(
  data = data.table(paris_pred1),
  id.vars = c("H_SEQ","F_SHARE","PRED_TURNOUT"),
  measure.vars = names(unmake_pc_vote_names))

paris_pred2_gg <- melt(
  data = data.table(paris_pred2),
  id.vars = c("H_SEQ","F_SHARE","PRED_TURNOUT"),
  measure.vars = names(unmake_pc_vote_names))

paris_pred_gg <- rbind(
  cbind("DIR" = "Direction to vertex", paris_pred1_gg),
  cbind("DIR" = "General direction", paris_pred2_gg))

paris_pred_gg[,COMPO := as.character(variable)]
paris_pred_gg[,SAHRE_XY := factor(unmake_pc_vote_names[COMPO], unmake_pc_vote_names)]
paris_pred_gg[,COMPO := fcase(grepl("^VOTE.",variable), "Changes in Y",
                              grepl("^PROFCAT.",variable), "Changes in X")]
paris_pred_gg[,COMPO := factor(COMPO, levels = c("Changes in Y", "Changes in X"))]

hline <- data.frame(
  INT = c(paris$PROFCAT[c(1,1), "Upper"],.25),
  DIR = c("Direction to vertex","General direction", "General direction"))

pclim <- c(.05, .95)
ggplot(paris_pred_gg) +
  geom_vline(aes(xintercept = INT), data = hline[1:2,]) +
  geom_line(aes(y = value, x = F_SHARE, col =SAHRE_XY, lty = SAHRE_XY)) +
  scale_y_continuous(breaks = seq(1,9, by = 2)/10, labels = scales::percent) +
  scale_x_continuous(breaks = seq(1,9, by = 2)/10, labels = scales::percent) +
  theme_bw() +
  labs(y = "predicted share of votes (bottom) or professional category (top)", x = "share of professional category Upper",
       col = "professional category\n(first four)\n\nvote shares\n(five to ten)",
       lty = "professional category\n(first four)\n\nvote shares\n(five to ten)") +
  facet_grid(rows = vars(COMPO), cols = vars(DIR), shrink = TRUE, scales = "free_y")

ggsave(here("out/figures", "yx_compo_variation_scatter.pdf"), height = 5.5, width = 7)
```


We can draw the same graphic as a function of the distance of $h$, which coorresponds in our case to the Aitchison distrance between $X(0)$ and $X(h)$.


```{r}
ggplot(paris_pred_gg[,]) +
  geom_vline(aes(xintercept = B), data = cbind(hline[1:2,],B = 0)) +
  geom_line(aes(y = value, x = as.integer(H_SEQ)/10, col =SAHRE_XY, lty = SAHRE_XY)) +
  scale_y_continuous(breaks = seq(1,9, by = 2)/10, labels = scales::percent) +
  # scale_x_continuous(breaks = seq(1,9, by = 2)/10, labels = scales::percent) +
  theme_bw() +
  labs(y = "predicted share of votes (bottom) or professional category (top)",
       x = "value of h",
       col = "professional category\n(first four)\n\nvote shares\n(five to ten)",
       lty = "professional category\n(first four)\n\nvote shares\n(five to ten)") +
  facet_grid(rows = vars(COMPO), cols = vars(DIR), shrink = TRUE, scales = "free_y")

ggsave(here("out/figures", "yx_compo_variation_scatter_by_h.pdf"), height = 5.5, width = 7)
```

Focusing on the first three components of each for the two compositions the same graphic can be shown in a matrix of ternary diagrams.


```{r}
#| fig-show: hold
opar <- par(mfrow = c(2,2), mai = c(.1,0,.2,0))
filter1 <- paris_pred1$H_SEQ[between(paris_pred1$F_SHARE, pclim[1], pclim[2])]
filter1 <- as.numeric(filter1)
filter1 <- min(max(-filter1), max(filter1))
filter1 <- intersect(paris_pred1$H_SEQ, seq(-filter1,filter1))
filter1 <- as.character(seq(-25,25))
colors1 <- diverging_hcl(length(filter1),palette = "Blue-Red-3", rev = T)


plot(acomp(paris_pred1$PROFCAT[filter1,1:3]),  col = colors1, pch = 19)
title("Change X (direction to vertex)")
plot(acomp(paris_pred2$PROFCAT[filter1,1:3]),  col = colors1, pch = 19)
title("Change X (general direction)")
plot(acomp(paris_pred1$VOTE[filter1,1:3]),  col = colors1, pch = 19)
plot(acomp(paris_pred2$VOTE[filter1,1:3]),  col = colors1, pch = 19)
par(opar)
```

```{r}
#| include: false
opar <- par(mfrow = c(1,2), mai = c(0,0.6,0,.6))
plot(acomp(paris_pred1$PROFCAT[filter1,1:3]),  col = colors1, pch = 19)
plot(acomp(paris_pred1$VOTE[filter1,1:3]),  col = colors1, pch = 19)
save_baseplot(pdf, here("out/figures", "yx_compo_variation_ternary_Xe.pdf"), height = 3, width = 7)

opar <- par(mfrow = c(1,2), mai = c(0,0.6,0,.6))
plot(acomp(paris_pred2$PROFCAT[filter1,1:3]),  col = colors1, pch = 19)
plot(acomp(paris_pred2$VOTE[filter1,1:3]),  col = colors1, pch = 19)
save_baseplot(pdf, here("out/figures", "yx_compo_variation_ternary_Xu.pdf"), height = 3, width = 7)
par(opar)
```


### Share ratio tables

```{r}
ShareRatioTable <- function(
  object,
  Xvar,
  Xdir, 
  as_matrix = FALSE){
  
  
  stopifnot(is(object, "lmCoDa"),
            is.character(Xvar) && length(Xvar) == 1,
            is.numeric(Xdir))
  
  trSry <- object$trSry
  Xcomp_names <- names(Filter(function(x) x>=1, trSry$D[-1]))
  Xcomp_names <- unlist(trSry$NAME_SIMPLEX[Xcomp_names])
  if (!Xvar %in% Xcomp_names) stop("Xvar musst be one of ", list(Xcomp_names), "!")
  Xpos <- which(unlist(trSry$NAME_SIMPLEX) == Xvar)
  if (trSry$D[[Xpos]] != length(Xdir) || any(Xdir <= 0)) stop("Xvar musst be a non-negative vector of length ", trSry$D[Xvar], "!")
  if (trSry$D[1] == 0) stop("Share ratio tables are only implemented when X and Y are compositional!")
  
  
  B  <- trSry$COEF_CLR[[Xpos]]
  u  <- Xdir/sum(Xdir)
  uB <- log(u) %*% B
  resY <- cbind(
    expand.grid(Yj  = colnames(B), Yl = colnames(B)),
    expand.grid(uBj = t(uB)      , uBl = t(uB)))
  resX <- cbind(
    expand.grid(Xj  = rownames(B), Xl = rownames(B)),
    expand.grid(uj  = log(u)     , ul = log(u)))
  
  resY <- resY[resY$Yj != resY$Yl,]
  resX <- resX[resX$Xj != resX$Xl,]
  resXY <- merge(resY, resX)
  resXY$SR <- (resXY$uBj - resXY$uBl) / (resXY$uj - resXY$ul)
  resXY[c("uBj","uBl","uj","ul")] <- NULL
  if (!as_matrix) return(resXY)
  
  
  Dx <- trSry$D[[Xpos]]
  Dy <- trSry$D[[1]]
  resMat <- matrix(resXY$SR,ncol = Dx^2 - Dx, nrow = Dy^2 - Dy)
  rownames(resMat) <- paste0(resY$Yj, "/", resY$Yl)
  colnames(resMat) <- paste0(resX$Xj, "/", resX$Xl)
  return(resMat)
  
}
```


```{r}
sr_tab <- ShareRatioTable(VOTE_model,Xvar = "PROFCAT", Xdir = dir_gen)
sr_tab$Yr <- paste0(as.character(sr_tab$Yj), " / ",as.character(sr_tab$Yl))
sr_tab$Xr <- paste0(as.character(sr_tab$Xj), " / ",as.character(sr_tab$Xl))
sr_tab$Yr <- factor(sr_tab$Yr, (unique(sr_tab$Yr)))
sr_tab$Xr <- factor(sr_tab$Xr, (unique(sr_tab$Xr)))

ggplot(sr_tab) +
  geom_point(aes(x = Yr, y = Xr, col = SR, pch = SR > 0), size = 5) +
  coord_fixed() +
  scale_color_continuous_diverging(rev = T,na.value = "white") +
  scale_shape_manual(breaks = c(T,F), values = c(20,18)) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90,hjust = 1, vjust = .5)) +
  labs(x = "Share ratio of Y", y = "Share ratio of X", col = "SRy / SRx", shape = "SRy / SRx > 0")

ggsave(here("out/figures/xy_compo_share_ratio_matrix.pdf"), height = 5)
```



# Acknowledgements {-}

The example used to illustrate this work is taken from a Statistical Consulting project class of the Master in Data Science for Social Sciences of The Toulouse School of economics, in cooperation with he Market Research agency BVA.
The project was a great experience and we want thank again all participants.
This includes Olivier Hennebelle and Alejandro Lara who advised the project from the side of BVA and our four students, Claire Lebrun, Malo Bert, Kyllian James and Gael Charrier.

