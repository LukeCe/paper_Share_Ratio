---
title: "Modeling the French presidential elections of 2022 with CoDa tools"
author:
  - Lukas Dargel
  - Christine Thomas-Agnan
format:
  html:
    theme: minty
    toc: true
    number-sections: true
    code-fold: true
    code-tools: true
    df-print: kable
    embed-resources: true
    standalone: true
    self-contained: true
execute:
  cache: true
  fig-show: hold
---

```{r}
#| include: false
dir.create(here::here("out","figures"),showWarnings = FALSE,recursive = TRUE)
```



```{r setup}
#| warning: false
#| message: false
library("colorspace")
library("CoDaImpact")
library("compositions")
library("data.table")
library("here")
library("ggplot2")
library("kableExtra")
library("skimr")
library("stringr")
library("zCompositions")

save_baseplot <- function(device, ..., which){
  suppressMessages({
    dev.copy(device, ..., which)
    dev.off()
    invisible(TRUE)
  })
}

options(knitr.kable.NA = '',
        scipen = 9,
        warn = 1)

mun_elec2census <- readRDS(here("out/data/mun_elec2census.Rds")) # election data combined with the census
mun_elec <- readRDS(here("in/data/mun_elec.Rds")) # original election data 
```


The vignette illustrates results of the article from Dargel and Thomas-Agnan (2023).


# Introduction

We illustrate the use of CoDa tools to analyse the results of political elections based on the example of the French presidential elections of 2022.
Our main focus lays on the illustration of mathematical tools that enable new ways for interpretation of CoDa models.
Other issues such as the selection of explanatory variables and the treatment of zeros are treated more briefly.


# Descriptive statistics

The study combine the official election results with census data.

  -  [The original census data is available on the INSEE website](https://www.insee.fr/fr/statistiques/6543200#consulter)
  -  [The official election results are provided by the French government and can be dowloaded here](https://www.data.gouv.fr/fr/datasets/election-presidentielle-des-10-et-24-avril-2022-resultats-definitifs-du-1er-tour/)
  

## Data overview 

Let us have a first look at the combined data set.

```{r}
skim(mun_elec2census)
```


## Compare losses due to preprocessing 


Let us compare the original voting data with the combined voting data to assess the losses and potential biases.


```{r}
rename_elec <- c(
  MACRON_Emmanuel = "Macron",
  LE_PEN_Marine = "Le Pen",
  MELENCHON_Jean_Luc = "Mélenchon",
  LEFT = "Left",
  RIGHT = "Right",
  NON_VOTE = "No vote",
  ARTHAUD_Nathalie = "Arthaud",
  ROUSSEL_Fabien = "Roussel",
  LASSALLE_Jean = "Lasalle",
  ZEMMOUR_Eric = "Zemmour",
  HIDALGO_Anne = "Hidalgo",
  JADOT_Yannick = "Jadot",
  PECRESSE_Valerie = "Pécresse",
  POUTOU_Philippe = "Poutou",
  DUPONT_AIGNAN_Nicolas = "Dupont-Aignan",
  ABSTENTIONS = "Abstention",
  BLANK = "Blank",
  INVALID = "Invalid",
  EXPRESSED = "Expressed",
  REGISTERED = "Registered")

```


```{r}
# original election columns
elec_cols <- setdiff(names(mun_elec), c("ID_MUN", "NAME_MUN", "NAME_DEP"))
pct <- function(x) scales::percent(x,accuracy = .1)
summarize_elec <- function(dt) {
  
  dt <- data.table(
    Municipalities = nrow(dt),
    Departements = length(unique(dt$NAME_DEP)),
    dt[,lapply(.SD, sum), .SDcols = elec_cols]
  )
  
  
  dt[,EXPRESSED := NA]
  dt[,REGISTERED := sum(.SD), .SDcols = elec_cols]
  dt[,EXPRESSED := REGISTERED - ABSTENTIONS - BLANK - INVALID]
  
  show_dt <- data.table(t(dt),keep.rownames = TRUE)
  
  dont_use <- c("Municipalities","Departements")
  show_dt[!rn %in% dont_use,
          "% of REGISTERED" := pct(V1/dt[["REGISTERED"]])]
  
  dont_use <- c(dont_use, "ABSTENTIONS", "BLANK", "INVALID", "REGISTERED")
  show_dt[!rn %in% dont_use,
          "% of EXPRESSED" := pct(V1/dt[["EXPRESSED"]])]
  names(show_dt)[1:2] <- c("Indicator", "Count")
  show_dt
}  

elec_original <- summarize_elec(mun_elec)
elec_combined <- summarize_elec(mun_elec2census)
elec_combined <- cbind(Loss = elec_original[["Count"]] - elec_combined[["Count"]], elec_combined[,-1])
elec_combined <- cbind("% Loss" = pct(elec_combined[["Loss"]]/elec_combined[["Count"]]), elec_combined)
elec_original[Indicator %in% names(rename_elec),Indicator := rename_elec[Indicator]]
kable(cbind(elec_original, elec_combined)) |> 
  kable_classic(full_width = F) |> 
  add_header_above(c(" " = 1, "Full election data" = 3, "Combined election data" = 5)) |> 
  pack_rows(group_label = "Units", 1,2,hline_after = TRUE) |> 
  pack_rows(group_label = "Not expressed", 3,5,hline_after = TRUE) |> 
  pack_rows(group_label = "Expressed", 6,17,hline_after = TRUE) |> 
  pack_rows(group_label = "Totals", 18,19,hline_after = TRUE) |> 
  column_spec(1, bold = T) 
```


## Check for problems with zeros

Since CoDa models do not handle zero proportions in either the dependent or independent compositional variables we have to treat the problem of zero before going to the modelling phase.
Here we a combination of amalgamations and imputations which corresponds to merging several components and replacing zeros with small values.
We do not claim any sociological validity for the grouping of candidates and professional categories
While the grouping we propose is based our intuitive understanding a true study of electoral sociology should place much more thought in these actions.

### In the vote data

We first check for zeros in the dependent variables.

```{r}
zero_summary <- function(dt) dt[,lapply(.SD, function(x) pct(sum(x==0)/.N))]
t(zero_summary(mun_elec2census[,..elec_cols]))
```

One way to solve the problem is amalgamations.
We see that almost $98.5\%$ of observations are complete now.

```{r}
left_bloc <- c("ARTHAUD_Nathalie", "ROUSSEL_Fabien", "HIDALGO_Anne", "JADOT_Yannick", "POUTOU_Philippe")
right_bloc <- c("ZEMMOUR_Eric", "PECRESSE_Valerie", "LASSALLE_Jean", "DUPONT_AIGNAN_Nicolas")

VOTE <- cbind(
  mun_elec2census[,c("MACRON_Emmanuel", "LE_PEN_Marine", "MELENCHON_Jean_Luc")],
  LEFT = as.integer(rowSums(mun_elec2census[,..left_bloc])),
  RIGHT = as.integer(rowSums(mun_elec2census[,..right_bloc])),
  NON_VOTE = as.integer(rowSums(mun_elec2census[,c("ABSTENTIONS", "INVALID","BLANK"),])))

colnames(VOTE) <- rename_elec[colnames(VOTE)]

vote_names <- rename_elec[colnames(VOTE)]
zPatterns(
  VOTE,
  bar.labels = TRUE,
  label="0")
```

`r zv <- sum(0 != rowSums(VOTE == 0))`
The remaining zeros are imputed.
Here take the simple road of adding 1 for to all lines with at least one zero.
Here we impute data in `r zv` cases with `r zv*ncol(VOTE)` additional "inscriptions".


```{r}
is_zero_row <- 0 != rowSums(VOTE == 0) 
VOTE_IMP <- VOTE + is_zero_row

cbind(
  sum(is_zero_row),
  sum(is_zero_row) * ncol(VOTE),
  sum(VOTE_IMP) - sum(VOTE))
```

#### Before and after

Let us check the impact of the imputation on the distribution of the data.
We see that our imputation leads an increase in the variance, but does not affect the average in a noticeable way.
This is expected because our imputation method replaces zeros (red bars in the graphic) with points close to the edge of the triangle, which are extreme values in the simplex sense.

```{r}
#| fig-show: "hold"

simplex_isodensity <- function(
  data,
  quantiles = c(0.5,1:9,9.5)/10,
  labels = names(cen),
  col1 = "black",
  col2 = "grey45",
  plot_data = TRUE) {
  
  # code adapted from:
  # Van den Boogaart and Tolosana-Delgado (2013), page 52
  
  stopifnot(ncol(data) == 3)
  cen <- mean(data)
  var <- var(data)
  if (plot_data) 
    plot(data, pch = ".", col = "grey85", labels = labels, mp = NULL, lenMissingTck = 0.02)
  plot(cen,pch=4, col = col1, labels = labels, add = plot_data)
  for (p in quantiles) {
    r = sqrt(qchisq(p=p,df=2))
    ellipses(cen,var,r, col=col2)
  }
}

opar <- par(mar=c(0,3,0,3), mfrow = c(1,2))
simplex_isodensity(acomp(VOTE_IMP[,1:3]))
title(sub = "Imputed", outer = FALSE)
simplex_isodensity(acomp(VOTE[,1:3]))
title(sub = "Original")
par(opar)
```

```{r}
#| fig-show: "hold"
opar <- par(mar=c(0,3,0,3), mfrow = c(1,2))
simplex_isodensity(acomp(VOTE_IMP[,-(1:3)]))
title(sub = "Imputed", outer = FALSE)
simplex_isodensity(acomp(VOTE[,-(1:3)]))
title(sub = "Original")
par(opar)
```



### In the professional categories (PC) data

The professional categories data directly comes from the French population census provided by the INSEE.
It categorizes the population above the age of 15 into one of eight groups.
The categories correspond to

  + `C19_POP15P_CS1`: Agriculteurs exploitants
  + `C19_POP15P_CS2`: Artisans, Commerçants, Chefs d'entreprise
  + `C19_POP15P_CS3`: Cadres et Professions intellectuelles supérieures
  + `C19_POP15P_CS4`: Professions intermédiaires
  + `C19_POP15P_CS5`: Employés
  + `C19_POP15P_CS6`: Ouvriers
  + `C19_POP15P_CS7`: Retraités
  + `C19_POP15P_CS8`: Autres sans activité professionnelle


```{r}
pc_cols <- names(mun_elec2census)
pc_cols <- pc_cols[grep("^C19_", pc_cols)]
t(zero_summary(mun_elec2census[,..pc_cols]))
```

Since the number of municipalities having zero share of some of these categories is to large we proceed with an amalgamation of the eight original groups into four broader categories.
Using the new categorization about  $95%$ of the municipalities have are complete.

```{r}
PROFCAT <- cbind(
  "Knowledge" = mun_elec2census[,C19_POP15P_CS3 + C19_POP15P_CS4],
  "Workers"   = mun_elec2census[,C19_POP15P_CS5 + C19_POP15P_CS6],
  "Retired"   = mun_elec2census[,C19_POP15P_CS7],
  "Other"     = mun_elec2census[,C19_POP15P_CS1 + C19_POP15P_CS2 + C19_POP15P_CS8]
)

zPatterns(
  PROFCAT,
  label="0",
  bar.labels = TRUE,
  axis.labels = c(NA,NA))
```

`r zv <- sum(0 != rowSums(PROFCAT == 0))`
We impute the data using the same strategy as before.
Here we impute data in `r zv` municipalities leading to `r zv*ncol(PROFCAT)` additional "inscriptions".

```{r}
is_zero_row <- 0 != rowSums(PROFCAT == 0) 
PROFCAT_IMP <- PROFCAT + is_zero_row
cbind(
  sum(is_zero_row),
  sum(is_zero_row) * ncol(PROFCAT),
  sum(PROFCAT_IMP) - sum(PROFCAT))
```

#### Before and after imputation

We have the same results as before, but the increase in variance appears more pronounced.

```{r}
#| fig-show: "hold"
opar <- par(mar=c(0,4,0,4), mfrow = c(1,2))
simplex_isodensity(acomp(PROFCAT_IMP[,(1:3)]))
title(sub = "Imputed", outer = FALSE)
simplex_isodensity(acomp(PROFCAT[,(1:3)]))
title(sub = "Original")
par(opar)
```

```{r}
#| fig-show: "hold"
opar <- par(mar=c(0,3,0,3), mfrow = c(1,2))
simplex_isodensity(acomp(PROFCAT_IMP[,(2:4)]))
title(sub = "Imputed", outer = FALSE)
simplex_isodensity(acomp(PROFCAT[,(2:4)]))
title(sub = "Original")
par(opar)
```


# Exploratory analysis


We defined the data set for our analysis.
Which is based on the imputed vote and professional categories (PC) data.


```{r}
mun2explore <- data.table(
  ID_MUN = mun_elec2census$ID_MUN,
  REGISTERED = rowSums(VOTE_IMP))
mun2explore <- cbind(mun2explore, VOTE_IMP, PROFCAT_IMP)
```


## Concentration

(Not yet ready)


## Heteroskedasticity


Since election data corresponds to aggregations of individual choices we should suspect heteroskedasticity.
The scatter plot below shows that that the share of "non votes" is directly impacted by the total number of voters.
Additionally, its volatility seems to decrease with the size of the municipality in terms number if voters.

```{r}
#| warning: false
#| message: false
ggplot(mun2explore[REGISTERED < 300000,], aes(x = sqrt(REGISTERED), y = `No vote`/REGISTERED)) +
  geom_point() +
  geom_smooth() +
  theme_bw() +
  theme()
```

A similar pattern is observed for all vote variables.

```{r}
#| fig-show: hold
seq125 <- c(0, unlist(lapply(10^seq(10), "*", c(1,2,5))))
seqSqr <- seq(0,15)^2 * 1000 
namesSqr <- c(
  sprintf("..., %s]", seqSqr[-1]), 
  sprintf("(%s, ...", seqSqr[length(seqSqr)]))
mun2explore[,REGISTERED_BINS := cut(REGISTERED,c(seqSqr,Inf),labels = namesSqr)]
mun2explore_long <- 
  melt(mun2explore,
       id.vars = c("ID_MUN","REGISTERED_BINS"),
       measure.vars = colnames(VOTE))

mun2explore_long[,value_rel := value/sum(value), by = "ID_MUN"]
mun2explore_long[,variable:=factor(variable, levels = rename_elec)]
ggplot(mun2explore_long, aes(x = REGISTERED_BINS, y = value_rel)) +
  geom_boxplot(outlier.size = .1) +
  facet_wrap("variable", ncol = 3) +
  scale_y_continuous(name = "Vote share",labels = scales::percent) +
  labs(x = "Number of registered voters") +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90,hjust = 1,vjust = .5)) 

ggsave(here("out/figures", "vote6_boxplots.pdf"), width = 7, height = 6)
```


For the profession categories we have the same pattern.

```{r}
#| fig-show: hold
mun2explore_long2 <- 
  melt(mun2explore,
       id.vars = c("ID_MUN","REGISTERED_BINS"),
       measure.vars = colnames(PROFCAT))

mun2explore_long2[,value_rel := value/sum(value), by = "ID_MUN"]
ggplot(mun2explore_long2, aes(x = REGISTERED_BINS, y = value_rel)) +
  geom_boxplot(outlier.size = .1) +
  facet_wrap("variable", ncol = 2) +
  scale_y_continuous(name = "Vote share",labels = scales::percent) +
  labs(x = "Number of registered voters") +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90,hjust = 1,vjust = .5))

ggsave(here("out/figures", "profcat4_boxplots.pdf"), width = 7, height = 6)
```



```{r}
# after the imputations we decide on the data that is used for modelling
mun2model <- data.frame(
  ID_MUN = mun_elec2census$ID_MUN,
  REGISTERED = rowSums(as.matrix(VOTE_IMP)),
  REGISTERED_G = Reduce("*", lapply(VOTE_IMP, as.numeric)))
mun2model[["VOTE"]] <- as.matrix(VOTE_IMP)/mun2model$REGISTERED
mun2model[["PROFCAT"]] <- as.matrix(PROFCAT_IMP)/rowSums(PROFCAT_IMP)
```


# Understanding "linear" changes in compositional variables

Here illustrate how compositional variables change using based on the composition of semiprofessional categories in Paris.
In the next section we will show how these changes affect the dependent variable on a model.
Below we have the observed composition for the Paris municipality.

```{r}
paris_id <- "75056"
paris <- mun2model[mun2model$ID_MUN == paris_id,,drop = FALSE]
paris$PROFCAT
```

In the following two subsections take this point of departure and add a sequence of linear increments, where linearity is understood with respect to the geometry of the simplex.
It should be evident that a linear increment of a multivariate vector is defined by a direction (which we normalize to unit length) and a step size.

## Changing in direction of first vertex

```{r}
paris_pcseq1 <- CoDa_path(
  comp_direc = c(2,1,1,1),
  comp_from = paris$PROFCAT,
  add_opposite = TRUE,
  step_size = .1) # take the same step size as before
```

Here we consider the direction that points from the original composition to directly to the first vertex of the simplex.
For our example the first vertex identifies the share of "Knowledge" workers.
Moving along this direction has the special property that the subcomposition that excludes the first element remains constant after closure.
This becomes evident when looking at the two ternary diagrams below, where the first shows the subcomposition that excludes "Other" and the second the one that excludes "Knowledge".
The composition observed for Paris is shown as a red cross.

```{r}
#| fig-show: hold
#| message: false
#| fig-pos: h
opar <- par(mfrow = c(1,2),oma = c(0,0,0,0))
plot.acomp(paris_pcseq1[,-4])
plot.acomp(paris_pcseq1["0",-4, drop = FALSE], col = "red", add = TRUE, pch = 3, cex = 2)

plot.acomp(paris_pcseq1[,-1])
plot.acomp(paris_pcseq1["0",-1, drop = FALSE], col = "red", add = TRUE, pch = 3, cex = 2)

save_baseplot(pdf, here("out/figures/","Xe_change_ternary.pdf"), width = 7, height = 4)
par(opar)
```
Both graphics above make clear that the ratios between all components except the first stay constant.
This also explains why the path in the left ternary plot appears linear in euclidean sense.
The same changes can be visualized in a stacked bar-plot, where the ratio of bar heights for the remains constant except when "Knowlege" is involved.
Here we only show changes for the steps defined by $h = -50,...,50$.

```{r}
#| fig-show: hold
names(paris_pcseq1) <- colnames(PROFCAT)
window <- as.character(seq(-40,40,by = 2))
barplot(acomp(paris_pcseq1[window,,drop=FALSE]))
save_baseplot(pdf, here("out/figures","Xe_change_barplot.pdf"))
```

Another way to look at the changing composition is to present the changes to all components as a function of the share of "Knowlege".
In this graphic we additionally display the empirical distribution of the share of "Knowlege" over all municipalities.
The vertical line intersects the other at the observed composition for Paris, showing that Paris is an outlier in the "Knowlege" dimension.

```{r}
#| fig-show: hold
paris_pcseq1_gg <- data.frame(paris_pcseq1)
colnames(paris_pcseq1_gg) <- paste0("PC", 1:4)
ggplot(paris_pcseq1_gg) +
  geom_vline(xintercept = paris$PROFCAT[[1]]) +
  geom_line(aes(x = PC1, y = PC1, col = "1", lty = "1"), lwd = .51) +
  geom_line(aes(x = PC1, y = PC2, col = "2", lty = "2"), lwd = .51) +
  geom_line(aes(x = PC1, y = PC3, col = "3", lty = "3"), lwd = .51) +
  geom_line(aes(x = PC1, y = PC4, col = "4", lty = "4"), lwd = .51) +
  geom_hline(yintercept = 1, col = "black") +
  geom_boxplot(
    data = data.frame(PC1 = mun2model$PROFCAT[,1]),
    mapping = aes(x = PC1, y = 1 + .0625),
    varwidth = TRUE,
    size = .5,
    col = "red",
    alpha = .25,
    width = .05) +
  scale_x_continuous(
    labels = scales::percent,
    sec.axis = dup_axis(name= "Boxplot of % in professional category: Knowlege")) +
  scale_y_continuous(
    labels = scales::percent,breaks = seq(0,1,.25)) +
  scale_color_manual(
    breaks = c("1","2", "3", "4"),
    values = c("Red", "Orange", "Dark Blue", "Yellow"),
    name = "professional\ncategory",
    labels = colnames(PROFCAT)) +
  scale_linetype_manual(
    breaks = c("1","2", "3", "4"),
    values = 1:4,
    name = "professional\ncategory",
    labels = colnames(PROFCAT)) +
  labs(x = "% in professional category: Knowlege",
       y = "% in professional category") +
  coord_equal() +
  theme_bw()

ggsave(here("out/figures/Xe_change_scatter.pdf"), height = 6, width = 6)
```

## Changing in direction of the origin

```{r}
paris_pcseq2 <- CoDa_path(
  comp_direc = paris$PROFCAT,
  comp_from = paris$PROFCAT,
  add_opposite = TRUE,
  step_size = attr(paris_pcseq1,"step_size")) # take the same step size as before
```

An alternative direction is the one that points from the observed point for Paris to the origin of the simplex.
The two ternary diagrams below show a path generated along this direction, where the red cross is the empirical composition for Paris and the blue star the origin.

```{r}
#| fig-show: "hold"
opar <- par(mfrow = c(1,2),oma = c(0,0,0,0))
plot.acomp(paris_pcseq2[,-4])
plot.acomp(paris_pcseq2["0",-4, drop = FALSE], col = "red", add = TRUE, pch = 3, cex = 2)
plot.acomp(c(1,1,1), col = "blue", add = TRUE, pch = 8, cex = 2)

plot.acomp(paris_pcseq2[,-1])
plot.acomp(paris_pcseq2["0",-1, drop = FALSE], col = "red", add = TRUE, pch = 3, cex = 2)
plot.acomp(c(1,1,1), col = "blue", add = TRUE, pch = 8, cex = 2)

save_baseplot(pdf, here("out/figures/","Xu_change_ternary.pdf"), width = 7, height = 4)
par(opar)
```

The simplex-linear path generated by this direction looks more complex because it is non-linear in euclidean sense.
For this path we also the ratios of the other components are no-longer constant and the changes are generally also not monotonic.
This becomes evident when looking the shares of "Other" and "Retired" that peak close to the center of our variation and decline towards both edges.


```{r}
names(paris_pcseq2) <- colnames(PROFCAT)
window <- as.character(seq(-40,40,by = 2))
barplot(acomp(paris_pcseq2[window,,drop=FALSE]))
save_baseplot(pdf, here("out/figures/","Xu_change_barplot.pdf"))
```

When looking at the functional representation of this linear path we clearly see that the shares for each professional category cross at the origin of the 4-dimensional simplex.
The intersection with the black line is again the empirical composition of Paris.

```{r}
#| fig-show: hold
paris_pcseq2_gg <- data.frame(paris_pcseq2)
colnames(paris_pcseq2_gg) <- paste0("PC", 1:4)
ggplot(paris_pcseq2_gg) +
  geom_vline(xintercept = paris$PROFCAT[[1]]) +
  geom_vline(xintercept = 1/4, col = "grey55") +
  geom_line(aes(x = PC1, y = PC1, col = "1", lty = "1"), lwd = .51) +
  geom_line(aes(x = PC1, y = PC2, col = "2", lty = "2"), lwd = .51) +
  geom_line(aes(x = PC1, y = PC3, col = "3", lty = "3"), lwd = .51) +
  geom_line(aes(x = PC1, y = PC4, col = "4", lty = "4"), lwd = .51) +
  geom_hline(yintercept = 1, col = "black") +
  geom_boxplot(
    data = data.frame(PC1 = mun2model$PROFCAT[,1]),
    mapping = aes(x = PC1, y = 1 + .0625),
    varwidth = TRUE,
    size = .5,
    col = "red",
    alpha = .25,
    width = .05) +
  scale_x_continuous(
    labels = scales::percent,
    sec.axis = dup_axis(name= "Boxplot of % in professional category: Knowlege")) +
  scale_y_continuous(
    labels = scales::percent,breaks = seq(0,1,.25)) +
  scale_color_manual(
    breaks = c("1","2", "3", "4"),
    values = c("Red", "Orange", "Dark Blue", "Yellow"),
    name = "professional\ncategory",
    labels = colnames(PROFCAT)) +
  scale_linetype_manual(
    breaks = c("1","2", "3", "4"),
    values = 1:4,
    name = "professional\ncategory",
    labels = colnames(PROFCAT)) +
  labs(x = "% in professional category: Knowlege",
       y = "% in professional category") +
  coord_equal() +
  theme_bw()

ggsave(here("out/figures/Xu_change_scatter.pdf"), height = 6, width = 6)
```

# Y-scalar model interpretations


In this section we look at a model that explains a transformation of the turnout rate, which we treat as a real variables.


```{r}
logit <- function(p) log(p/(1-p))
TURNOUT_model <- lm(
  logit(1 - VOTE[,6]) ~  ilr(PROFCAT) + log(REGISTERED),
  data = mun2model,
  weights = REGISTERED)
summary(TURNOUT_model)
```
## Interpreting the impact of scalar X

Constant marginal effects.

## Interpreting the impact of compositional X

Constant semi-elasticities.

### Semi-elasticites

In this model the clr transformed coefficient correspond directly to the semi-elasticity of the shares.

```{r}
#| fig-show: hold
#| warning: false
clr_confint <- CoDaImpact:::confint.clr(TURNOUT_model, "ilr(PROFCAT)")

ggplot(clr_confint) +
  theme_bw() +
  coord_flip() +
  geom_hline(yintercept = 0) +
  geom_segment(aes(x=X, xend=X, y=0, yend=EST, col = X)) +
  geom_point(aes(x=X, y = EST, col = X)) +
  geom_point(aes(x=X, y = Q025, col = X), pch = "[", stroke = 3) +
  geom_point(aes(x=X, y = Q975, col = X), pch = "]", stroke = 3) +
  labs(y = "semi-elasticities values & confidence intervals", x = NULL) +
  theme(legend.position = "none")

ggsave(here("out/figures", "yscalar_elasticity_profcat.pdf"), height = 2, width = 7)
```


### Variation scenario

We now evaluate how the two scenarios of changes in the socio-professional composition of Paris would impact the vote shares of each candidate.
The scenarios where the share of knowledge worker below $5\%$ or above $95\%$ were discarded since they are to extreme.
We see that both scenarios pass through the observed composition for Paris and lead to a predicted turnout of about $72.9\%$.
In the hypothetical scenario where Paris has equal population in each professional category the turnout is predicted to drop to about $67\%$.


```{r}
#| fig-show: hold
#| warning: false
inv_logit <- function(x) 1/(1 + exp(-x))
paris_pred1 <- paris[rep(1,nrow(paris_pcseq1)),]
paris_pred1$PROFCAT <- as.matrix(paris_pcseq1)
paris_pred1$VOTE <- NULL
paris_pred1$PRED_TURNOUT_LOGIT <- CoDaImpact:::predict.lmSimplex(TURNOUT_model, newdata = paris_pred1) 
paris_pred1$PRED_TURNOUT <- inv_logit(paris_pred1$PRED_TURNOUT_LOGIT)
paris_pred1$H_SEQ <- row.names(paris_pred1) <- row.names(paris_pcseq1)
paris_pred1$F_SHARE <- paris_pred1$PROFCAT[,"Knowledge"]

paris_pred1_gg <- melt(
  data = data.table(paris_pred1),
  id.vars = c("H_SEQ","F_SHARE","PRED_TURNOUT_LOGIT","PRED_TURNOUT"),
  measure.vars = paste0("PROFCAT.", colnames(PROFCAT)))

paris_pred2 <- paris[rep(1,nrow(paris_pcseq2) + 1),]
paris_pred2$PROFCAT <- rbind(as.matrix(paris_pcseq2),rep(.25,4))
paris_pred2$VOTE <- NULL
paris_pred2$PRED_TURNOUT_LOGIT <- CoDaImpact:::predict.lmSimplex(TURNOUT_model, newdata = paris_pred2) 
paris_pred2$PRED_TURNOUT <- inv_logit(paris_pred2$PRED_TURNOUT_LOGIT)
paris_pred2$H_SEQ <- row.names(paris_pred2) <- c(row.names(paris_pcseq2),"101")
paris_pred2$F_SHARE <- paris_pred2$PROFCAT[,"Knowledge"]

paris_pred2_gg <- melt(
  data = data.table(paris_pred2),
  id.vars = c("H_SEQ","F_SHARE","PRED_TURNOUT_LOGIT","PRED_TURNOUT"),
  measure.vars = paste0("PROFCAT.", colnames(PROFCAT)))

paris_pred_gg <- rbind(
  cbind("DIR" = "Direction with vertex", paris_pred1_gg),
  cbind("DIR" = "General direction", paris_pred2_gg))
paris_pred_gg[,variable := str_remove(variable,"PROFCAT.")]

hline <- data.frame(
  INT = c(paris_pred1[c("0","0"), "PRED_TURNOUT"],paris_pred2["101", "PRED_TURNOUT"]),
  DIR = c("Direction with vertex","General direction", "General direction"),
  LAB = c("(Paris)","(Paris)", "(origin)"),
  YYY = c(.85),
  JJJ = c(-.5,-.5,1.5))

pclim <- c(.05, .95)
ggplot(paris_pred_gg[between(F_SHARE, pclim[1], pclim[2]),]) +
  geom_vline(aes(xintercept = INT), data = hline) +
  geom_text(aes(x = INT, y = YYY, label = LAB, vjust = JJJ), data = hline) +
  geom_line(aes(y = value, x = PRED_TURNOUT, col =variable, lty = variable)) +
  scale_y_continuous(breaks = seq(0,10)/10,labels = scales::percent) +
  scale_x_continuous(labels = scales::percent,sec.axis = dup_axis(name = NULL)) +
  coord_fixed() +
  coord_flip() +
  theme_bw() +
  labs(y = "share in professional category", x = "predicted turnout",
       col = "professional\ncategory", lty = "professional\ncategory") +
  facet_wrap("DIR", nrow = 2, scales = "free_x")

ggsave(here("out/figures/x_compo_variation_scatter.pdf"), height = 5, width = 7)
```

# Y-compositional model interpretations

Here we look at the case of a Y-compositional model that explains the full composition of votes.

```{r}
VOTE_model <- lm(
  ilr(VOTE) ~  ilr(PROFCAT) + log(REGISTERED),
  data = mun2model)
summary(VOTE_model)
```

## Interpreting the impact of scalar X


### Finite increments


### Semi-elasticities diffrence

The clr coefficients correspond to a difference from a mean elasticity.

```{r}
#| fig-show: hold
#| warning: false
flevels <- c("Mean elasticity", rev(rename_elec))
clr_confint <- CoDaImpact:::confint.clr(VOTE_model, "log(REGISTERED)")
clr_confint$Y <- factor(clr_confint$Y, flevels)
clr_confintB <- clr_confint[1,]
clr_confintB$Y <- factor("Mean elasticity", levels = flevels)
clr_confintB[,3:6] <- NA
trSry <- CoDaImpact:::transformationSummary(VOTE_model)
clr_T <- Reduce("rbind", trSry$COEF_CLR[-1])
ME <- as(ilrInv(VOTE_model$fitted.values),"matrix") %*% t(clr_T[-1,])
ME <- melt(data.table(ME), variable.name = "X", value.name = "EST")
ME[,Y := factor("Mean elasticity", levels = flevels)]

ggplot(rbind(clr_confint,clr_confintB)) +
  theme_bw() +
  coord_flip() +
  geom_hline(yintercept = 0) +
  geom_segment(aes(x=Y, xend=Y, y=0, yend=EST, col = Y)) +
  geom_point(aes(x=Y, y = EST, col = Y)) +
  geom_point(aes(x=Y, y = Q025, col = Y), pch = "[", stroke = 3) +
  geom_point(aes(x=Y, y = Q975, col = Y), pch = "]", stroke = 3) +
  geom_violin(aes(y = EST, x = Y),data = ME[X=="log(REGISTERED)",]) +
  labs(y = "clr parameter values & confidence intervals\ndistribution of mean elasticity", x = NULL) +
  theme(legend.position = "none")

ggsave(here("out/figures", "clr_b_profcat.pdf"), height = 2.5, width = 7)
```


We can use them to construct differences between the elasticities of two components of the dependent shares with respect to the same variable.

```{r}
#| fig-show: hold
#| warning: false
clr_confint <- CoDaImpact:::confint.clr(VOTE_model, "log(REGISTERED)",y_ref = 1)
clr_confint$Y <- factor(clr_confint$Y, flevels)
clr_confintB <- clr_confint[1,]
clr_confintB[,3:6] <- NA

ggplot(rbind(clr_confint,clr_confintB)) +
  theme_bw() +
  coord_flip() +
  geom_hline(yintercept = 0) +
  geom_segment(aes(x=Y, xend=Y, y=0, yend=DIFF, col = Y)) +
  geom_point(aes(x=Y, y = DIFF, col = Y)) +
  geom_point(aes(x=Y, y = Q025, col = Y), pch = "[", stroke = 3) +
  geom_point(aes(x=Y, y = Q975, col = Y), pch = "]", stroke = 3) +
  labs(y = "semi-elasticity differences & confidence intervals\n(reference is the share of Macron)", x = NULL) +
  theme(legend.position = "none")

ggsave(here("out/figures", "SE_diff_profcat.pdf"), height = 2, width = 7)
```

### Variation scenarios

In this scenario we suppose that the number of registered voter changes on a grid that is regular in logs.
Even for the extreme changes such as a tenfold increase of the population or reduction to one tenth would not lead to a lot of variation.
When Paris is shrunk to the size of a village with $1000$ registered voters we see considerable differences.

```{r}
#| fig-show: hold
paris_size_scenario <- paris[rep(1,101),]
paris_size_scenario$REGISTERED <- paris_size_scenario$REGISTERED * exp(seq(-log(1000),log(10),length.out = 101))
paris_size_scenario$VOTE <- as(CoDaImpact:::predict.lmSimplex(VOTE_model, newdata = paris_size_scenario), "matrix")
colnames(paris_size_scenario$VOTE) <- colnames(VOTE)

paris_size_scenario_gg <- melt(
  data = data.table(paris_size_scenario),
  id.vars = "REGISTERED",
  measure.vars = make.names(paste0("VOTE.",colnames(VOTE))))


unmake_votenames <- structure(colnames(VOTE), names = make.names(paste0("VOTE.",colnames(VOTE))))
paris_size_scenario_gg[,variable := factor(unmake_votenames[variable],unmake_votenames)]
ggplot(paris_size_scenario_gg) +
  geom_vline(xintercept = paris$REGISTERED) +
  geom_line(aes(x = REGISTERED, y = value, col = variable, lty = variable)) +
  scale_x_continuous(trans = "log10") +
  scale_y_continuous(labels = scales::percent) +
  labs(y = "vote share", x = "number of registered voters", col = "candidate", lty = "candidate") +
  theme_bw()

ggsave(here("out/figures","y_compo_variation_scatter.pdf"), height = 5, width = 7)
```



## Interpreting the impact of a X-compositional variable

### Finite increments

### Elasticities difference

For X-compositional variables the clr coefficients also correspond to differences in mean elasticities, where these means are computed for each component of $X$ over all dependent shares.

```{r}
#| fig-show: hold
#| warning: false
clr_confint <- CoDaImpact:::confint.clr(VOTE_model, "ilr(PROFCAT)")
clr_confint$Y <- factor(clr_confint$Y,levels = flevels)
clr_confint_all <- clr_confint
clr_confint_all$Y <- factor("Mean elasticity", flevels)
clr_confint_all$SD <- clr_confint_all$EST
clr_confint_all$EST <- NA
clr_confint_all$Q025 <- NA
clr_confint_all$Q975 <- NA
clr_confint_all <- unique(clr_confint_all)

ggplot(rbind(clr_confint,clr_confint_all)) +
  theme_bw() +
  coord_flip() +
  geom_hline(yintercept = 0) +
  geom_segment(aes(x=Y, xend=Y, y=0, yend=EST, col = Y)) +
  geom_point(aes(x=Y, y = EST, col = Y)) +
  geom_point(aes(x=Y, y = Q025, col = Y), pch = "[", stroke = 3) +
  geom_point(aes(x=Y, y = Q975, col = Y), pch = "]", stroke = 3) +
  geom_violin(aes(y = EST, x = Y),data = ME[X!="log(REGISTERED)"]) +
  facet_wrap("X") +
  labs(y = "clr parameter values & confidence intervals\ndistribution of mean elasticity", x = NULL) +
  theme(legend.position = "none")

ggsave(here("out/figures", "clr_B_profcat.pdf"), height = 4, width = 7)
```


```{r}
#| fig-show: hold
#| warning: false
clr_confint <- CoDaImpact:::confint.clr(VOTE_model, "ilr(PROFCAT)",y_ref = 1)
clr_confint$Y <- factor(clr_confint$Y,levels = flevels)
ggplot(clr_confint) +
  theme_bw() +
  coord_flip() +
  geom_hline(yintercept = 0) +
  geom_segment(aes(x=Y, xend=Y, y=0, yend=DIFF, col = Y)) +
  geom_point(aes(x=Y, y = DIFF, col = Y)) +
  geom_point(aes(x=Y, y = Q025, col = Y), pch = "[", stroke = 3) +
  geom_point(aes(x=Y, y = Q975, col = Y), pch = "]", stroke = 3) +
  facet_wrap("X") +
  labs(y = "elasticity differnces & confidence intervals\n(reference is the share of Macron)", x = NULL) +
  theme(legend.position = "none")

ggsave(here("out/figures", "E_diff_profcat.pdf"), height = 3.5, width = 7)
```


### Variation scenarios

Turning to the changes induced by the variation of the socio-professional composition in Paris.
Here we show the changes in the explanatory composition on top of the changes in the predicted shares.

```{r}
paris_pred1$VOTE <- as(CoDaImpact:::predict.lmSimplex(VOTE_model, newdata = paris_pred1),"matrix")
paris_pred2$VOTE <- as(CoDaImpact:::predict.lmSimplex(VOTE_model, newdata = paris_pred2),"matrix")
unmake_pc_vote_names <- c(
  structure(paste0("(PC) ", colnames(PROFCAT)), names = paste0("PROFCAT.", colnames(PROFCAT))),
  structure(paste0("(Vote) ", unmake_votenames), names = names(unmake_votenames)))

paris_pred1_gg <- melt(
  data = data.table(paris_pred1),
  id.vars = c("H_SEQ","F_SHARE","PRED_TURNOUT_LOGIT","PRED_TURNOUT"),
  measure.vars = names(unmake_pc_vote_names))

paris_pred2_gg <- melt(
  data = data.table(paris_pred2),
  id.vars = c("H_SEQ","F_SHARE","PRED_TURNOUT_LOGIT","PRED_TURNOUT"),
  measure.vars = names(unmake_pc_vote_names))

paris_pred_gg <- rbind(
  cbind("DIR" = "Vertex as direction", paris_pred1_gg),
  cbind("DIR" = "General direction", paris_pred2_gg))

paris_pred_gg[,COMPO := as.character(variable)]
paris_pred_gg[,SAHRE_XY := factor(unmake_pc_vote_names[COMPO], unmake_pc_vote_names)]
paris_pred_gg[,COMPO := fcase(grepl("^VOTE.",variable), "Changes in Y",
                              grepl("^PROFCAT.",variable), "Changes in X")]


hline <- data.frame(
  INT = c(paris$PROFCAT[c(1,1), "Knowledge"],.25),
  DIR = c("Vertex as direction","General direction", "General direction"))

ggplot(paris_pred_gg[between(F_SHARE, pclim[1], pclim[2]),]) +
  geom_vline(aes(xintercept = INT), data = hline) +
  geom_line(aes(y = value, x = F_SHARE, col =SAHRE_XY, lty = SAHRE_XY)) +
  scale_y_continuous(breaks = seq(1,9, by = 2)/10, labels = scales::percent) +
  scale_x_continuous(breaks = seq(1,9, by = 2)/10, labels = scales::percent) +
  theme_bw() +
  labs(y = "predicted share of votes (bottom) or professional category (top)", x = "share of professional category Knowlege",
       col = "professional category\n(first four)\n\nvote shares\n(five to ten)",
       lty = "professional category\n(first four)\n\nvote shares\n(five to ten)") +
  facet_grid(rows = vars(COMPO), cols = vars(DIR), shrink = TRUE, scales = "free_y")

ggsave(here("out/figures", "yx_compo_variation_scatter.pdf"), height = 5.5, width = 7)
```


Focusing on the first three components of each for the two compositions the same graphic can be shown in a matrix of ternary diagrams.


```{r}
#| fig-show: hold
opar <- par(mfrow = c(2,2), mai = c(.1,0,.2,0))
filter1 <- paris_pred1$H_SEQ[between(paris_pred1$F_SHARE, pclim[1], pclim[2])]
filter1 <- max(as.numeric(filter1))
filter1 <- intersect(paris_pred1$H_SEQ, seq(-filter1,filter1))
colors1 <- diverging_hcl(length(filter1),palette = "Blue-Red-3", rev = T)


filter2 <- paris_pred2$H_SEQ[between(paris_pred2$F_SHARE, pclim[1], pclim[2])]
filter2 <- min(as.numeric(filter2))
filter2 <- intersect(paris_pred2$H_SEQ, seq(-filter2,filter2))
colors2 <- diverging_hcl(length(filter2),palette = "Blue-Red-3", rev = T)

plot(acomp(paris_pred1$PROFCAT[filter1,1:3]),  col = colors1, pch = 19)
title("Change X (direction vertex)")
plot(acomp(paris_pred2$PROFCAT[filter2,1:3]),  col = colors1, pch = 19)
title("Change X (general direction)")
plot(acomp(paris_pred1$VOTE[filter1,1:3]),  col = colors1, pch = 19)
plot(acomp(paris_pred2$VOTE[filter2,1:3]),  col = colors1, pch = 19)
par(opar)
save_baseplot(pdf, here("out/figures", "yx_compo_variation_ternary_with_title.pdf"), height = 5.5, width = 7)
```

```{r include=TRUE}
opar <- par(mfrow = c(2,2), mai = c(0.1,0,0,0))
plot(acomp(paris_pred1$PROFCAT[filter1,1:3]),  col = colors1, pch = 19)
plot(acomp(paris_pred2$PROFCAT[filter2,1:3]),  col = colors1, pch = 19)
plot(acomp(paris_pred1$VOTE[filter1,1:3]),  col = colors1, pch = 19)
plot(acomp(paris_pred2$VOTE[filter2,1:3]),  col = colors1, pch = 19)
par(opar)
save_baseplot(pdf, here("out/figures", "yx_compo_variation_ternary.pdf"), height = 5.5, width = 7)
```



# Acknowlegements {-}

The example used to illustrate this work is taken from a Statistical Consulting project class of the Master in Data Science for Social Sciences of The Toulouse School of economics, in cooperation with he Market Research agency BVA.
The project was a great experience and we want thank again all participants.
This includes Olivier Hennebelle and Alejandro Lara who advised the project from the side of BVA and our four students, Claire Lebrun, Malo Bert, Kyllian James and Gael Charrier.

