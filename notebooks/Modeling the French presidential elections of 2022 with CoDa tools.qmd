---
title: "Modeling the French presidential elections of 2022 with CoDa tools"
author:
  - Lukas Dargel
  - Christine Thomas-Agnan
format:
  html:
    theme: minty
    toc: true
    number-sections: true
    code-fold: true
    code-tools: true
    df-print: kable
    embed-resources: true
    standalone: true
    self-contained: true
execute:
  cache: true
  fig-show: "hold"
---

```{r}
#| include: false
dir.create(here::here("out","figures"),showWarnings = FALSE,recursive = TRUE)
```



```{r setup}
#| warning: false
#| message: false
library("CoDaImpact")
library("compositions")
library("data.table")
library("here")
library("ggplot2")
library("kableExtra")
library("skimr")
library("zCompositions")


options(knitr.kable.NA = '',
        scipen = 9)

mun_elec2census <- readRDS(here("out/data/mun_elec2census.Rds")) # election data combined with the census
mun_elec <- readRDS(here("in/data/mun_elec.Rds")) # original election data 
```


The vignette illustrates results of the article from Dargel and Thomas-Agnan (2023).


# Introduction

We illustrate the use of CoDa tools to analyse the results of political elections based on the example of the French presidential elections of 2022.
Our main focus lays on the illustration of mathematical tools that enable new ways for interpretation of CoDa models.
Other issues such as the selection of explanatory variables and the treatment of zeros are treated more briefly.


# Descriptive statistics

The study combine the official election results with census data.

  -  [The original census data is available on the INSEE website](https://www.insee.fr/fr/statistiques/6543200#consulter)
  -  [The official election results are provided by the French government and can be dowloaded here](https://www.data.gouv.fr/fr/datasets/election-presidentielle-des-10-et-24-avril-2022-resultats-definitifs-du-1er-tour/)
  

## Data overview 

Let us have a first look at the combined data set.

```{r}
skim(mun_elec2census)
```


## Compare losses due to preprocessing 


Let us compare the original voting data with the combined voting data to assess the losses and potential biases.


```{r}
rename_elec <- c(
  MACRON_Emmanuel = "Macron",
  LE_PEN_Marine = "Le Pen",
  MELENCHON_Jean_Luc = "Mélenchon",
  LEFT = "Left",
  RIGHT = "Right",
  NON_VOTE = "No vote",
  ARTHAUD_Nathalie = "Arthaud",
  ROUSSEL_Fabien = "Roussel",
  LASSALLE_Jean = "Lasalle",
  ZEMMOUR_Eric = "Zemmour",
  HIDALGO_Anne = "Hidalgo",
  JADOT_Yannick = "Jadot",
  PECRESSE_Valerie = "Pécresse",
  POUTOU_Philippe = "Poutou",
  DUPONT_AIGNAN_Nicolas = "Dupont-Aignan",
  ABSTENTIONS = "Abstention",
  BLANK = "Blank",
  INVALID = "Invalid",
  EXPRESSED = "Expressed",
  REGISTERED = "Registered")

```


```{r}
# original election columns
elec_cols <- setdiff(names(mun_elec), c("ID_MUN", "NAME_MUN", "NAME_DEP"))
pct <- function(x) scales::percent(x,accuracy = .1)
summarize_elec <- function(dt) {
  
  dt <- data.table(
    Municipalities = nrow(dt),
    Departements = length(unique(dt$NAME_DEP)),
    dt[,lapply(.SD, sum), .SDcols = elec_cols]
  )
  
  
  dt[,EXPRESSED := NA]
  dt[,REGISTERED := sum(.SD), .SDcols = elec_cols]
  dt[,EXPRESSED := REGISTERED - ABSTENTIONS - BLANK - INVALID]
  
  show_dt <- data.table(t(dt),keep.rownames = TRUE)
  
  dont_use <- c("Municipalities","Departements")
  show_dt[!rn %in% dont_use,
          "% of REGISTERED" := pct(V1/dt[["REGISTERED"]])]
  
  dont_use <- c(dont_use, "ABSTENTIONS", "BLANK", "INVALID", "REGISTERED")
  show_dt[!rn %in% dont_use,
          "% of EXPRESSED" := pct(V1/dt[["EXPRESSED"]])]
  names(show_dt)[1:2] <- c("Indicator", "Count")
  show_dt
}  

elec_original <- summarize_elec(mun_elec)
elec_combined <- summarize_elec(mun_elec2census)
elec_combined <- cbind(Loss = elec_original[["Count"]] - elec_combined[["Count"]], elec_combined[,-1])
elec_combined <- cbind("% Loss" = pct(elec_combined[["Loss"]]/elec_combined[["Count"]]), elec_combined)
elec_original[Indicator %in% names(rename_elec),Indicator := rename_elec[Indicator]]
kable(cbind(elec_original, elec_combined)) |> 
  kable_classic(full_width = F) |> 
  add_header_above(c(" " = 1, "Full election data" = 3, "Combined election data" = 5)) |> 
  pack_rows(group_label = "Units", 1,2,hline_after = TRUE) |> 
  pack_rows(group_label = "Not expressed", 3,5,hline_after = TRUE) |> 
  pack_rows(group_label = "Expressed", 6,17,hline_after = TRUE) |> 
  pack_rows(group_label = "Totals", 18,19,hline_after = TRUE) |> 
  column_spec(1, bold = T) 
```


## Check for problems with zeros

Since CoDa models do not handle zero proportions in either the dependent or independent compositional variables we have to treat the problem of zero before going to the modelling phase.
Here we a combination of amalgamations and imputations which corresponds to merging several components and replacing zeros with small values.
We do not claim any sociological validity for the grouping of candidates and professional categories
While the grouping we propose is based our intuitive understanding a true study of electoral sociology should place much more thought in these actions.

### In the vote data

We first check for zeros in the dependent variables.

```{r}
zero_summary <- function(dt) dt[,lapply(.SD, function(x) pct(sum(x==0)/.N))]
t(zero_summary(mun_elec2census[,..elec_cols]))
```

One way to solve the problem is amalgamations.
We see that almost $98.5\%$ of observations are complete now.

```{r}
left_bloc <- c("ARTHAUD_Nathalie", "ROUSSEL_Fabien", "HIDALGO_Anne", "JADOT_Yannick", "POUTOU_Philippe")
right_bloc <- c("ZEMMOUR_Eric", "PECRESSE_Valerie", "LASSALLE_Jean", "DUPONT_AIGNAN_Nicolas")

VOTE <- cbind(
  mun_elec2census[,c("MACRON_Emmanuel", "LE_PEN_Marine", "MELENCHON_Jean_Luc")],
  LEFT = as.integer(rowSums(mun_elec2census[,..left_bloc])),
  RIGHT = as.integer(rowSums(mun_elec2census[,..right_bloc])),
  NON_VOTE = as.integer(rowSums(mun_elec2census[,c("ABSTENTIONS", "INVALID","BLANK"),])))

vote_names <- rename_elec[colnames(VOTE)]
zPatterns(
  `names<-`(VOTE,vote_names),
  bar.labels = TRUE,
  label="0")
```

`r zv <- sum(0 != rowSums(VOTE == 0))`
The remaining zeros are imputed.
Here take the simple road of adding 1 for to all lines with at least one zero.
Here we impute data in `r zv` cases with `r zv*ncol(VOTE)` additional "inscriptions".


```{r}
is_zero_row <- 0 != rowSums(VOTE == 0) 
VOTE_IMP <- VOTE + is_zero_row
cbind(
  sum(is_zero_row),
  sum(is_zero_row) * ncol(VOTE),
  sum(VOTE_IMP) - sum(VOTE))
```

#### Before and after

Let us check the impact of the imputation on the distribution of the data.
We see that our imputation leads an increase in the variance, but does not affect the average in a noticeable way.
This is expected because our imputation method replaces zeros (red bars in the graphic) with points close to the edge of the triangle, which are extreme values in the simplex sense.

```{r}
#| fig-show: "hold"

simplex_isodensity <- function(
  data,
  quantiles = c(0.5,1:9,9.5)/10,
  labels = names(cen),
  col1 = "black",
  col2 = "grey45",
  plot_data = TRUE) {
  
  # code adapted from:
  # Van den Boogaart and Tolosana-Delgado (2013), page 52
  
  stopifnot(ncol(data) == 3)
  cen <- mean(data)
  var <- var(data)
  if (plot_data) 
    plot(data, pch = ".", col = "grey85", labels = labels, mp = NULL, lenMissingTck = 0.02)
  plot(cen,pch=4, col = col1, labels = labels, add = plot_data)
  for (p in quantiles) {
    r = sqrt(qchisq(p=p,df=2))
    ellipses(cen,var,r, col=col2)
  }
}

opar <- par(mar=c(0,3,0,3), mfrow = c(1,2))
simplex_isodensity(acomp(VOTE_IMP[,1:3]), labels = c("Macron", "Le Pen", "Mélenchon"))
title(sub = "Imputed", outer = FALSE)
simplex_isodensity(acomp(VOTE[,1:3]), labels = c("Macron", "Le Pen", "Mélenchon"))
title(sub = "Original")
par(opar)
```

```{r}
#| fig-show: "hold"

opar <- par(mar=c(0,3,0,3), mfrow = c(1,2))
simplex_isodensity(acomp(VOTE_IMP[,-(1:3)]), labels = c("Left", "Right", "No vote"))
title(sub = "Imputed", outer = FALSE)
simplex_isodensity(acomp(VOTE[,-(1:3)]), labels = c("Left", "Right", "No vote"))
title(sub = "Original")
par(opar)
```



### In the professional categories (PC) data

The professional categories data directly comes from the French population census provided by the INSEE.
It categorizes the population above the age of 15 into one of eight groups.
The categories correspond to

  + `C19_POP15P_CS1`: Agriculteurs exploitants
  + `C19_POP15P_CS2`: Artisans, Commerçants, Chefs d'entreprise
  + `C19_POP15P_CS3`: Cadres et Professions intellectuelles supérieures
  + `C19_POP15P_CS4`: Professions intermédiaires
  + `C19_POP15P_CS5`: Employés
  + `C19_POP15P_CS6`: Ouvriers
  + `C19_POP15P_CS7`: Retraités
  + `C19_POP15P_CS8`: Autres sans activité professionnelle


```{r}
pc_cols <- names(mun_elec2census)
pc_cols <- pc_cols[grep("^C19_", pc_cols)]
t(zero_summary(mun_elec2census[,..pc_cols]))
```

Since the number of municipalities having zero share of some of these categories is to large we proceed with an amalgamation of the eight original groups into four broader categories.
Using the new categorization about  $95%$ of the municipalities have are complete.

```{r}
PROFCAT <- cbind(
  "Knowledge" = mun_elec2census[,C19_POP15P_CS3 + C19_POP15P_CS4],
  "Workers"   = mun_elec2census[,C19_POP15P_CS5 + C19_POP15P_CS6],
  "Retired"   = mun_elec2census[,C19_POP15P_CS7],
  "Other"     = mun_elec2census[,C19_POP15P_CS1 + C19_POP15P_CS2 + C19_POP15P_CS8]
)

zPatterns(
  PROFCAT,
  label="0",
  bar.labels = TRUE,
  axis.labels = c(NA,NA))
```

`r zv <- sum(0 != rowSums(PROFCAT == 0))`
We impute the data using the same strategy as before.
Here we impute data in `r zv` municipalities leading to `r zv*ncol(PROFCAT)` additional "inscriptions".

```{r}
is_zero_row <- 0 != rowSums(PROFCAT == 0) 
PROFCAT_IMP <- PROFCAT + is_zero_row
cbind(
  sum(is_zero_row),
  sum(is_zero_row) * ncol(PROFCAT),
  sum(PROFCAT_IMP) - sum(PROFCAT))
```

#### Before and after imputation

We have the same results as before, but the increase in variance appears more pronounced.

```{r}
#| fig-show: "hold"
opar <- par(mar=c(0,4,0,4), mfrow = c(1,2))
simplex_isodensity(acomp(PROFCAT_IMP[,(1:3)]))
title(sub = "Imputed", outer = FALSE)
simplex_isodensity(acomp(PROFCAT[,(1:3)]))
title(sub = "Original")
par(opar)
```

```{r}
#| fig-show: "hold"
opar <- par(mar=c(0,3,0,3), mfrow = c(1,2))
simplex_isodensity(acomp(PROFCAT_IMP[,(2:4)]))
title(sub = "Imputed", outer = FALSE)
simplex_isodensity(acomp(PROFCAT[,(2:4)]))
title(sub = "Original")
par(opar)
```


# Exploratory analysis


We defined the data set for our analysis.
Which is based on the imputed vote and professional categories (PC) data.


```{r}
mun2explore <- data.table(
  ID_MUN = mun_elec2census$ID_MUN,
  REGISTERED = rowSums(VOTE_IMP))
mun2explore <- cbind(mun2explore, VOTE_IMP, PROFCAT_IMP)
```


## Concentration

(Not yet ready)


## Heteroskedasticity


Since election data corresponds to aggregations of individual choices we should suspect heteroskedasticity.
The scatter plot below shows that that the share of "non votes" is directly impacted by the total number of voters.
Additionally, its volatility seems to decrease with the size of the municipality in terms number if voters.

```{r}
ggplot(mun2explore[REGISTERED < 300000,], aes(x = sqrt(REGISTERED), y = NON_VOTE/REGISTERED)) +
  # geom_boxplot(aes(x = REGISTERED_BINS, y = ABSTENTIONS/REGISTERED)) +
  geom_point() +
  geom_smooth() +
  theme_bw() +
  theme()
```

A similar pattern is observed for all vote variables.

```{r}
seq125 <- c(0, unlist(lapply(10^seq(10), "*", c(1,2,5))))
seqSqr <- seq(0,15)^2 * 1000 
namesSqr <- c(
  sprintf("..., %s]", seqSqr[-1]), 
  sprintf("(%s, ...", seqSqr[length(seqSqr)]))
mun2explore[,REGISTERED_BINS := cut(REGISTERED,c(seqSqr,Inf),labels = namesSqr)]
mun2explore_long <- 
  melt(mun2explore,
       id.vars = c("ID_MUN","REGISTERED_BINS"),
       measure.vars = colnames(VOTE))

mun2explore_long[,value_rel := value/sum(value), by = "ID_MUN"]
mun2explore_long[,variable:=rename_elec[as.character(variable)]]
mun2explore_long[,variable:=factor(variable, levels = rename_elec)]
ggplot(mun2explore_long, aes(x = REGISTERED_BINS, y = value_rel)) +
  geom_boxplot(outlier.size = .1) +
  facet_wrap("variable", ncol = 3) +
  scale_y_continuous(name = "Vote share",labels = scales::percent) +
  labs(x = "Number of registered voters") +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90,hjust = 1,vjust = .5)) 

ggsave(here("out/figures", "vote6_boxplots.pdf"), width = 7, height = 6)
```


And for the PC variables as well.

```{r}
mun2explore_long2 <- 
  melt(mun2explore,
       id.vars = c("ID_MUN","REGISTERED_BINS"),
       measure.vars = colnames(PROFCAT))

mun2explore_long2[,value_rel := value/sum(value), by = "ID_MUN"]
ggplot(mun2explore_long2, aes(x = REGISTERED_BINS, y = value_rel)) +
  geom_boxplot(outlier.size = .1) +
  facet_wrap("variable", ncol = 2) +
  scale_y_continuous(name = "Vote share",labels = scales::percent) +
  labs(x = "Number of registered voters") +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90,hjust = 1,vjust = .5))

ggsave(here("out/figures", "profcat4_boxplots.pdf"), width = 7, height = 6)
```


##  Correlations


# Understanding "linear" changes in compositional variables

Here illustrate how compositional variables change using based on the composition of semiprofessional categories in Paris.
In the next section we will show how these changes affect the dependent variable on a model.
Below we have the observed composition for the Paris municipality.

```{r}
paris <- "75056"
paris <- mun2model[mun2model$ID_MUN == paris,,drop = FALSE]
paris$PROFCAT
```

In the following two subsections take this point of departure and add a sequence of linear increments, where linearity is understood with respect to the geometry of the simplex.
It should be evident that a linear increment of a multivariate vector is defined by a direction (which we normalize to unit length) and a step size.

## Changing in direction of first summit

```{r}
paris_pcseq1 <- CoDa_seq(
  comp_from = paris$PROFCAT,
  comp_to = c(1e10,1,1,1)*as.numeric(paris$PROFCAT),
  add_opposite = TRUE)
```

Here we consider the direction that points from the original composition to directly to the first summit of the simplex.
For our example the first summit identifies the share of "Knowledge" workers.
Moving along this direction has the special property that the subcomposition that excludes the first element remains constant after closure.
This becomes evident when looking at the two ternary diagrams below, where the first shows the subcomposition that excludes "Other" and the second the one that excludes "Knowledge".
The composition observed for Paris is shown as a red cross.

```{r}
#| fig-show: "hold"
#| message: false
opar <- par(mfrow = c(1,2),oma = c(0,0,0,0))
plot.acomp(paris_pcseq1[,-4])
plot.acomp(paris_pcseq1["0",-4, drop = FALSE], col = "red", add = TRUE, pch = 3, cex = 2)

plot.acomp(paris_pcseq1[,-1])
plot.acomp(paris_pcseq1["0",-1, drop = FALSE], col = "red", add = TRUE, pch = 3, cex = 2)

dev.copy(pdf, here("out/figures/","Xe_change_ternary.pdf"), width = 7, height = 3)
dev.off()
par(opar)
```
Both graphics above make clear that the ratios between all components except the first stay constant.
This also explains why the path in the left ternary plot appears linear in euclidean sense.
The same changes can be visualized in a stacked bar-plot, where the ratio of bar heights for the remains constant except when "Knowlege" is involved.
Here we only show changes for the steps defined by $h = -20,...,20$.

```{r}
names(paris_pcseq1) <- colnames(PROFCAT)
window <- as.character(seq(-20,20,by = 1))

barplot(acomp(paris_pcseq1[window,,drop=FALSE]))
dev.copy(pdf, here("out/figures","Xe_change_barplot.pdf"))
dev.off()
```

Another way to look at the changing composition is to present the changes to all components as a function of the share of "Knowlege".
In this graphic we additionally display the empirical distribution of the share of "Knowlege" over all municipalities.
The vertical line intersects the other at the observed composition for Paris, showing that Paris is an outlier in the "Knowlege" dimension.

```{r}
paris_pcseq1_gg <- data.frame(paris_pcseq1)
colnames(paris_pcseq1_gg) <- paste0("PC", 1:4)
ggplot(paris_pcseq1_gg) +
  geom_vline(xintercept = paris$PROFCAT[[1]]) +
  geom_line(aes(x = PC1, y = PC1, col = "1", lty = "1"), lwd = .51) +
  geom_line(aes(x = PC1, y = PC2, col = "2", lty = "2"), lwd = .51) +
  geom_line(aes(x = PC1, y = PC3, col = "3", lty = "3"), lwd = .51) +
  geom_line(aes(x = PC1, y = PC4, col = "4", lty = "4"), lwd = .51) +
  geom_hline(yintercept = 1, col = "black") +
  geom_boxplot(
    data = data.frame(PC1 = mun2model$PROFCAT[,1]),
    mapping = aes(x = PC1, y = 1 + .0625),
    varwidth = TRUE,
    size = .5,
    col = "red",
    alpha = .25,
    width = .05) +
  scale_x_continuous(
    labels = scales::percent,
    sec.axis = dup_axis(name= "Boxplot of % in professional category: Knowlege")) +
  scale_y_continuous(
    labels = scales::percent,breaks = seq(0,1,.25)) +
  scale_color_manual(
    breaks = c("1","2", "3", "4"),
    values = c("Red", "Orange", "Dark Blue", "Yellow"),
    name = "professional\ncategory",
    labels = colnames(PROFCAT)) +
  scale_linetype_manual(
    breaks = c("1","2", "3", "4"),
    values = 1:4,
    name = "professional\ncategory",
    labels = colnames(PROFCAT)) +
  labs(x = "% in professional category: Knowlege",
       y = "% in professional category") +
  coord_equal() +
  theme_bw()

ggsave(here("out/figures/Xe_change_scatter.pdf"), height = 6, width = 6)
```


## Changing in direction of the origin

```{r}
paris_pcseq2 <- CoDa_path(
  comp_direc = paris$PROFCAT,
  comp_from = paris$PROFCAT,
  add_opposite = TRUE,
  step_size = attr(paris_pcseq1,"step_size")) # take the same step size as before
```

An alternative direction is the one that points from the observed point for Paris to the origin of the simplex.
The two ternary diagrams below show a path generated along this direction, where the red cross is the empirical composition for Paris and the blue star the origin.

```{r}
#| fig-show: "hold"
opar <- par(mfrow = c(1,2))
plot.acomp(paris_pcseq2[,-4])
plot.acomp(paris_pcseq2["0",-4, drop = FALSE], col = "red", add = TRUE, pch = 3, cex = 2)
plot.acomp(c(1,1,1), col = "blue", add = TRUE, pch = 8, cex = 2)

plot.acomp(paris_pcseq2[,-1])
plot.acomp(paris_pcseq2["0",-1, drop = FALSE], col = "red", add = TRUE, pch = 3, cex = 2)
plot.acomp(c(1,1,1), col = "blue", add = TRUE, pch = 8, cex = 2)
par(opar)

dev.copy(pdf, here("out/figures/","Xu_change_ternary.pdf"),
         width = 7,
         height = 3)
dev.off()
par(opar)
```

The simplex-linear path generated by this direction looks more complex because it is non-linear in euclidean sense.
For this path we also the ratios of the other components are no-longer constant and the changes are generally also not monotonic.
This becomes evident when looking the shares of "Other" and "Retired" that peak close to the center of our variation and decline towards both edges.


```{r}
names(paris_pcseq2) <- colnames(PROFCAT)
window <- as.character(seq(-60,60,by = 4))

barplot(acomp(paris_pcseq2[window,,drop=FALSE]))
dev.copy(pdf, here("out/figures/","Xu_change_barplot.pdf"))
dev.off()
```

When looking at the functional representation of this linear path we clearly see that the shares for each professional category cross at the origin of the 4-dimensional simplex.
The intersection with the black line is again the empirical composition of Paris.

```{r}
paris_pcseq2_gg <- data.frame(paris_pcseq2)
colnames(paris_pcseq2_gg) <- paste0("PC", 1:4)
ggplot(paris_pcseq2_gg) +
  geom_vline(xintercept = paris$PROFCAT[[1]]) +
  geom_vline(xintercept = 1/4, col = "grey55") +
  geom_line(aes(x = PC1, y = PC1, col = "1", lty = "1"), lwd = .51) +
  geom_line(aes(x = PC1, y = PC2, col = "2", lty = "2"), lwd = .51) +
  geom_line(aes(x = PC1, y = PC3, col = "3", lty = "3"), lwd = .51) +
  geom_line(aes(x = PC1, y = PC4, col = "4", lty = "4"), lwd = .51) +
  geom_hline(yintercept = 1, col = "black") +
  geom_boxplot(
    data = data.frame(PC1 = mun2model$PROFCAT[,1]),
    mapping = aes(x = PC1, y = 1 + .0625),
    varwidth = TRUE,
    size = .5,
    col = "red",
    alpha = .25,
    width = .05) +
  scale_x_continuous(
    labels = scales::percent,
    sec.axis = dup_axis(name= "Boxplot of % in professional category: Knowlege")) +
  scale_y_continuous(
    labels = scales::percent,breaks = seq(0,1,.25)) +
  scale_color_manual(
    breaks = c("1","2", "3", "4"),
    values = c("Red", "Orange", "Dark Blue", "Yellow"),
    name = "professional\ncategory",
    labels = colnames(PROFCAT)) +
  scale_linetype_manual(
    breaks = c("1","2", "3", "4"),
    values = 1:4,
    name = "professional\ncategory",
    labels = colnames(PROFCAT)) +
  labs(x = "% in professional category: Knowlege",
       y = "% in professional category") +
  coord_equal() +
  theme_bw()

ggsave(here("out/figures/Xu_change_scatter.pdf"), height = 6, width = 6)
```


# Y-scalar model interpretations


In this section we look at a model that explains a transformation of the share of "non votes", which we treat as a real variables.


```{r}
mun2model <- data.frame(
  ID_MUN = mun_elec2census$ID_MUN,
  REGISTERED = rowSums(as.matrix(VOTE_IMP)),
  REGISTERED_G = Reduce("*", lapply(VOTE_IMP, as.numeric)))
mun2model[["VOTE"]] <- as.matrix(VOTE_IMP)/mun2model$REGISTERED
mun2model[["PROFCAT"]] <- as.matrix(PROFCAT_IMP)/rowSums(PROFCAT_IMP)

logit <- function(p) log(p/(p+1))
NV_model <- lm(
  logit(VOTE[,6]) ~  ilr(PROFCAT) + log(REGISTERED),
  data = mun2model,
  weights = REGISTERED)
summary(NV_model)
```
## Interpreting the impact of scalar X

Constant marginal effects.

## Interpreting the impact of compositional X

Constant semi-elasticities.

### Semi-elasticites

In this model the clr transformed coefficient correspond directly to the semi-elasticity of the shares.

```{r}
#| warning: false
clr_confint <- CoDaImpact:::confint.clr(NV_model, "ilr(PROFCAT)")

ggplot(clr_confint) +
  theme_bw() +
  coord_flip() +
  geom_hline(yintercept = 0) +
  geom_segment(aes(x=X, xend=X, y=0, yend=EST, col = X)) +
  geom_point(aes(x=X, y = EST, col = X)) +
  geom_point(aes(x=X, y = Q025, col = X), pch = "[", stroke = 3) +
  geom_point(aes(x=X, y = Q975, col = X), pch = "]", stroke = 3) +
  labs(y = "semi-elasticities values & confidence intervals", x = NULL) +
  theme(legend.position = "none")

ggsave(here("out/figures", "yscalar_elasticity_profcat.pdf"), height = 2, width = 7)
```


### Variation scenario

We can now take the two sce


### Dependence profiles for the whole dataset



# Y-compositional model interpretations

Here we look at the case of a Y-compositional model that explains the full composition of votes.

```{r}
VOTE_model <- lm(
  ilr(VOTE) ~  ilr(PROFCAT) + log(REGISTERED),
  data = mun2model)
summary(VOTE_model)
```

## Interpreting the impact of scalar X


### Coefficients and Elasticities

The clr coefficients correspond to a difference from a mean elasticity.

```{r}
#| warning: false
flevels <- c("Mean elasticity", rev(rename_elec))
clr_confint <- CoDaImpact:::confint.clr(VOTE_model, "log(REGISTERED)")
clr_confint$Y <- factor(rename_elec[clr_confint$Y], flevels)
clr_confintB <- clr_confint[1,]
clr_confintB$Y <- factor("Mean elasticity", levels = flevels)
clr_confintB[,3:6] <- NA

ggplot(rbind(clr_confint,clr_confintB)) +
  theme_bw() +
  coord_flip() +
  geom_hline(yintercept = 0) +
  geom_segment(aes(x=Y, xend=Y, y=0, yend=EST, col = Y)) +
  geom_point(aes(x=Y, y = EST, col = Y)) +
  geom_point(aes(x=Y, y = Q025, col = Y), pch = "[", stroke = 3) +
  geom_point(aes(x=Y, y = Q975, col = Y), pch = "]", stroke = 3) +
  geom_boxplot(aes(y = EST, x = Y),data = data.frame(
    EST = clr_confint$EST,
    X = clr_confintB$Y,
    Y = "Mean elasticity")) +
  labs(y = "clr parameter values & confidence intervals\ndisribution of mean elasitcity", x = NULL) +
  theme(legend.position = "none")

ggsave(here("out/figures", "clr_b_profcat.pdf"), height = 2.5, width = 7)
```


We can use them to construct differences between the elasticities of two components of the dependent shares with respect to the same variable.

```{r}
#| warning: false
clr_confint <- CoDaImpact:::confint.clr(VOTE_model, "log(REGISTERED)",y_ref = 1)
clr_confint$Y <- factor(rename_elec[clr_confint$Y], flevels)
clr_confintB <- clr_confint[1,]
clr_confintB[,3:6] <- NA

ggplot(rbind(clr_confint,clr_confintB)) +
  theme_bw() +
  coord_flip() +
  geom_hline(yintercept = 0) +
  geom_segment(aes(x=Y, xend=Y, y=0, yend=DIFF, col = Y)) +
  geom_point(aes(x=Y, y = DIFF, col = Y)) +
  geom_point(aes(x=Y, y = Q025, col = Y), pch = "[", stroke = 3) +
  geom_point(aes(x=Y, y = Q975, col = Y), pch = "]", stroke = 3) +
  labs(y = "semi-elasticity differences & confidence intervals\n(reference is the share of Macron)", x = NULL) +
  theme(legend.position = "none")

ggsave(here("out/figures", "SE_diff_profcat.pdf"), height = 2, width = 7)
```



## Interpreting the impact of a X-compositional variable

For X-compositional variables the clr coefficients also correspond to differences in mean elasticities, where these means are computed for each component of $X$ over all dependent shares.

```{r}
#| warning: false
clr_confint <- CoDaImpact:::confint.clr(VOTE_model, "ilr(PROFCAT)")
clr_confint$Y <- factor(rename_elec[clr_confint$Y],levels = flevels)
clr_confint_all <- clr_confint
clr_confint_all$Y <- factor("Mean elasticity", flevels)
clr_confint_all$SD <- clr_confint_all$EST
clr_confint_all$EST <- NA
clr_confint_all$Q025 <- NA
clr_confint_all$Q975 <- NA
clr_confint_all <- unique(clr_confint_all)

ggplot(rbind(clr_confint,clr_confint_all)) +
  theme_bw() +
  coord_flip() +
  geom_hline(yintercept = 0) +
  geom_segment(aes(x=Y, xend=Y, y=0, yend=EST, col = Y)) +
  geom_point(aes(x=Y, y = EST, col = Y)) +
  geom_point(aes(x=Y, y = Q025, col = Y), pch = "[", stroke = 3) +
  geom_point(aes(x=Y, y = Q975, col = Y), pch = "]", stroke = 3) +
  geom_boxplot(aes(y = EST, x = Y),data = data.frame(
    EST = clr_confint_all$SD,
    X = clr_confint_all$X,
    Y = "Mean elasticity")) +
  facet_wrap("X") +
  labs(y = "clr parameter values & confidence intervals\ndisribution of mean elasitcity", x = NULL) +
  theme(legend.position = "none")

ggsave(here("out/figures", "clr_B_profcat.pdf"), height = 4, width = 7)
```


```{r}
#| warning: false
clr_confint <- CoDaImpact:::confint.clr(VOTE_model, "ilr(PROFCAT)",y_ref = 1)
clr_confint$Y <- factor(rename_elec[clr_confint$Y],levels = flevels)
ggplot(clr_confint) +
  theme_bw() +
  coord_flip() +
  geom_hline(yintercept = 0) +
  geom_segment(aes(x=Y, xend=Y, y=0, yend=DIFF, col = Y)) +
  geom_point(aes(x=Y, y = DIFF, col = Y)) +
  geom_point(aes(x=Y, y = Q025, col = Y), pch = "[", stroke = 3) +
  geom_point(aes(x=Y, y = Q975, col = Y), pch = "]", stroke = 3) +
  facet_wrap("X") +
  labs(y = "elasticity differnces & confidence intervals\n(reference is the share of Macron)", x = NULL) +
  theme(legend.position = "none")

ggsave(here("out/figures", "E_diff_profcat.pdf"), height = 3.5, width = 7)
```


## Variation scenarios



## Dependence profiles



# Acknowlegements {-}

The example used to illustrate this work is taken from a Statistical Consulting project class of the Master in Data Science for Social Sciences of The Toulouse School of economics, in cooperation with he Market Research agency BVA.
The project was a great experience and we want thank again all participants.
This includes Olivier Hennebelle and Alejandro Lara who advised the project from the side of BVA and our four students, Claire Lebrun, Malo Bert, Kyllian James and Gael Charrier.

